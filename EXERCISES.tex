%version of 01-21-20

\chapter{Solutions/Hints for selected exercises}
\label{ch:Exercises}



%\section*{Exercises: Chapter 2}

\begin{itemize}
\item
{\bf 2.2. Meeting people at a party}

{\em Some two attendees shake the same number of hands.}
\medskip

The pigeonhole principle guarantees that some two attendees shake the same
number of hands.  To wit, the number of people that each attendee {\em
  does not know} belongs to the set $\{ 0, 1, \ldots, 2n-2 \}$,
because each person knows him/herself and his/her partner.  

Since there are $2n$ handshakers (the pigeons) and $2n-1$ numbers of hands
to shake (the boxes), some two shakers must shake the same numbers of
hands. 
\medskip
\item
{\bf 2.4. Bi-colored necklaces in tubes}

You have a {\it necklace} composed of $2n$ jewels: $2a$ black jewels and $2b$ white jewels.  For illustration, the necklace in Fig.~\ref{fig:sample-necklace} has $n = 6$, $a = 5$, and $b =1$.
\begin{figure}[ht]
\begin{center}
       \includegraphics[scale=0.35]{FiguresMaths/SampleNecklace}
\caption{(a) A necklace having $12$ jewels: $10$ black and $2$ white.  (b) The necklace in a tube.}
\end{center}
\end{figure}

In part (a) of the figure, the necklace is unadorned; in part (b), the necklace appears within a length-$n$ {\it tube} which isolates one string---i.e., half-necklace---of $n$ jewels from the complementary string.

\smallskip

\noindent {\em For any bi-colored necklace, there is a way to position the tube so that inside the tube and outside the tube, 
there are equally many jewels, equally many black jewels, and equally many white jewels.} 
\smallskip

Slide the tube around the necklace, and count both black and white jewels at each step.  
How can these numbers change in a single step?
\medskip \item
{\bf 2.6. Using {\em geometric} intuition to sum inverse powers of $4$}

{\sc Lesson:} Exploiting geometric intuition toward a sophisticated end.

\smallskip

We turn to a variant of Proposition~\ref{thm:sumof-1/4-induction}.  This time, we focus on the entire infinite summation
\[ S \ \ = \ \  {1 \over 4} \ + \  {1 \over 4^2} \ + \cdots + \ {1 \over 4^k} \ + \cdots  \]
and we do so from a geometric point of view.

\smallskip

We prove in Proposition~\ref{thm:sum-finite-geometric-series}(b) that this infinite summation converges to the value ${1 \over 3}$.  A simple way to see this is to multiply the summation $S$ term by term by the fraction $1/4$.  We observe---just by inspection---that the resulting product, which clearly has the value $S/4$, equals $S - 1/4$, so that $S = 1/3$.

\smallskip

We have now described the process at a very high level.  
Your assignment is to flesh out the details.  {\em Prove that the four sub-triangles
\begin{itemize}
\item
are similar to one another
\item
are similar to the original triangle
\item
have area which is $1/4$ that of the original triangle
\end{itemize}
Assemble these facts into an evaluation of the sum $S$.
}

\noindent \textit{Solution.}
A rapid analysis of the small values of $k$ leads to the guess $(\frac{1}{4})^k = \frac{1}{3}$.
 
The solution is depicted in Fig.~\ref{Fig:Sumgeo1sur4}. 
\begin{figure}
\begin{center}
        \includegraphics[scale=0.3]{FiguresArithmetic/SumGeometric1sur4}
        \caption{Graphical construction. Assuming the total area is 1, the area of the grey internal triangle (left) is $\frac{1}{4}$.
        As the grey area is one third at each layer (right), the whole area is $\frac{1}{3}$.
        By the double counting Fubini's principle, this area is the sum of the $\frac{1}{4^k}$ (for $k \geq 1$).}
        \label{Fig:Sumgeo1sur4}
\end{center}
\end{figure}

Finding such a triangular pattern may not be considered as an easy task.
However, as stated in the problem, the main point is to divide an elementary surface
into four equal pieces. 
Squares (or even worse disks) are not simple to use in this context while isosceles triangles 
are a \textit{natural} structure. 

\end{itemize}

\ignore{*************************
\subsection{A graphical proof}

\noindent \textit{The problem.}
%\label{thm:an-arithmetic-identity}
Prove the following property:

or any positive integer $n$,
\[ \Delta_{2n-1} \ = \ n + 4 \Delta_{n-1}. \]
\medskip

\noindent \textit{The solution.}

Consider the arithmetic series in (\ref{eq:arith-seq}) for the case
$a=1$ and $b=4$.  
By Proposition~\ref{thm:sum-of-arithmetic-series},
this series, call it $S^{(1,4)}(n)$, has the sum
\begin{equation}
\label{eq:triangles}
S^{(1,4)}(n) \ = \ n + 4 \Delta_{n-1}.
\end{equation}

Let us represent the sum $\Delta_{n-1}$ in the natural way as a
triangle of tokens.  This triangle has a base of $n-1$ tokens, upon
which sits a row of $n-2$ tokens, upon which sits a row of $n-3$
tokens, \ldots, all the way to the apex, which has a single token.

Now, let us view equation (\ref{eq:triangles}) as giving us access to four
copies of the preceding triangle of tokens.  Let us arrange these
triangles in the manner depicted in Fig.~\ref{fig:Delta(n)4}.
\begin{figure}[ht]
\begin{center}
       \includegraphics[scale=0.5]{FiguresMaths/Delta4}
 \caption{Arranging the four triangles plus a row to obtain a new (bigger) triangle.}
       \label{fig:Delta(n)4}
\end{center}
\end{figure}
Now, ``complete the picture'' by adding an ``extra'' row of $n$
tokens at row $n$ of the figure (these are depicted in dark gray in
the figure).  The four small triangles, augmented by the ``extra'' row
of $n$ tokens has clearly become a representation  of $\Delta_{2n-1}$
by tokens.

We now have a purely pictorial proof of the proposition. 

*************************}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%\section*{Exercises of Chapter 3}

\begin{itemize}
\item
{\bf 3.8. More connections between strings and functions}
\medskip

{\em Craft an argument that predicts the number of permutations, based on the size of set $S$.}
\smallskip

\begin{itemize}
\item
As you create a new string of numbers, in how many ways can you choose {\em the first number}? 
{\em the second number}? \ldots
\item
Based on your answers for the first and second and third numbers of the new string, 
in how many ways can you choose {\em the first two numbers---i.e., the first {\em pair} of numbers}? 
{\em the next two numbers}? \ldots
\end{itemize}

{\em Strengthen your argument by listing all permutations of  $S' =  \{1,2,3,4,5\}$.}

\smallskip

Write small---there are a lot of permutations.

{\em Extrapolate from your argument to determine the number of permutations of the set 
$S" =  \{1,2,3, \ldots, n\}$, as a function of $n$.}

\end{itemize}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\section*{Exercises: Chapter 4}

\begin{itemize}
\item
{\bf 4.5. The rationals ($\Q$) and the integers ($\N$) are equinumerous}
\smallskip

{\em Provide a {\em detailed} proof of Proposition~\ref{thm:|Q|=|N|}.}  
Informally, there are equally many integers as there are rationals.
\end{itemize}


\ignore{***************************************
\subsection{Complex
  multiplication via $3$ real multiplications}
\index{complex number!multiplication via 3 real multiplications}

\noindent {\it The problem.}
%\label{thm:complex-mult-3real}
Show how to compute the product of two complex numbers using only {\em three}
real multiplications rather than four.
\medskip

\noindent {\it The solution.}
Although implementing (\ref{eq:complex-mult}) ``directly'' correctly
produces the product $\kappa = (a+bi) \cdot (c+di)$, there is another
implementation that is {\em more efficient}.  Specifically, the
following recipe computes $\kappa$ using only {\em three} real
multiplications instead of the four real multiplications of the
``direct'' implementation.  We begin to search for this recipe by
noting that our immediate goal is to compute both Re$(\kappa) = ac-bd$
and Im$(\kappa) = ad+bc$.  We can accomplish this by computing the
{\em three} real products
\begin{equation}
\label{eq:complex-mult-3a}
(a+b) \cdot (c+d); \ \ \ \ \
ac;  \ \ \ \ \ bd
\end{equation}
and then noting that
\begin{equation}
\label{eq:complex-mult-3b}
\begin{array}{lcl}
\mbox{Im}(\kappa) & = & (a+b) \cdot (c+d) - ac -bd, \\
\mbox{Re}(\kappa) & = & ac -bd
\end{array}
\end{equation}
We thereby achieve the result of the complex multiplication described
in (\ref{eq:complex-mult}) while using only {\em three} real
multiplications.


%%%
\subsection{Another proof for irrationality of $\sqrt{2}$}


\noindent \textit{The problem.}
Prove the irrationality of $\sqrt{2}$ using a geometrical argument.
\medskip

\noindent \textit{Hint.}
The proof is by contradiction. 

Consider $\sqrt{2}$ is rational, which means there exists a pair of integers $(a,b)$
such that $\sqrt{2} = \frac{a}{b}$ (where $a$ is larger than $b$).
Among all possible pairs, take the unique irreductible ratio.

Represent this expression geometrically by the corresponding isosceles triangle
which is the one of minimal surface. 

The contradiction comes by constructing another isosceles triangle with a smaller surface.
%Squaring this expression leads to $2.b^2 = a^2$.
\medskip

\noindent \textit{The solution.}

The solution is depicted in Fig.~\ref{Fig:sqrtbisInit} and~\ref{Fig:sqrtbisFin} . 
\begin{figure}
\begin{center}
        \includegraphics[scale=0.3]{FiguresArithmetic/sqrtbisInit}
        \caption{First step: folding the triangle along the side.}
        \label{Fig:sqrtbisInit}
\end{center}
\end{figure}
\begin{figure}
\begin{center}
        \includegraphics[scale=0.3]{FiguresArithmetic/sqrtbisFin}
        \caption{Second step. The sides of the small isosceles triangle are integers.}
        \label{Fig:sqrtbisFin}
\end{center}
\end{figure}
****************************}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\ignore{*******************************
\section{Chapter 5}


\subsection{A ``trick'' for squaring certain integers}


\noindent \textit{The problem:}

Let $n$ be any number that has a $2$-digit decimal numeral of the form

\hspace{.25in}$5.\delta$ \ \ \ \ $(\delta \in \{ 0,1,2,3,4,5,6,7,8,9\})$.

\noindent
Then the square of $n$ is the integer

\hspace{.25in}$25 \ + \ \delta \cdot (\delta +1)$
\medskip

\noindent \textit{The solution:}

We can rewrite the premise of the proposition in the form
\[ n \ = \ 10 \cdot \delta + 5 \]
It is now easy to invoke Proposition~\ref{prop:(a+b)(c+d)} and the
distributive law to compute that

\[ n^2 \ = \ 100 \cdot \delta \cdot (\delta+1) + 25 \]
To wit: 
\[
\begin{array}{lclll}
n^2 & = & (10 \cdot \delta + 5)^2 & & \mbox{Given} \\
    & = & 100 \cdot \delta^2 \ + \ 100 \cdot \delta \ + \ 25
              & & \mbox{the proposition} \\
    & = & 100 \cdot (\delta^2 \ + \ \delta) \ + \ 25
              & & \mbox{factoring: distributive law} \\
    & = & 100 \cdot \delta \cdot (\delta + 1) \ + \ 25
              & & \mbox{factoring: distributive law} \\
\end{array}
\]
A parlor trick has become a mathematical demonstration!


%%%
\subsection{Revisiting a very old problem}

\noindent \textit{The problem:}

This problem comes from babylonians in the 18th century BC.
The numeral system was in base 60, and the problem was to determine the length of the side of a square which was part of a larger rectangle.
The following figure details the process.
\medskip

\noindent \textit{The solution:}

The idea of the proof is to represent the left hand side by the square $x^2$ beside a rectangle $60 \times x$
(see Fig.~\ref{fig:equationBabillon}).
Recall that the coefficient of $x$ in the equation is $1$, this corresponds to $60$ in the considered basis. 
Then, split the right rectangle into two equal parts and move one part a the bottom of the left square.
The final figure shows the whole square whose surface is equal to $45$ plus the surface of the white square
whose surface is equal to $30 \times 30$.
In base $60$, this is equal to $15$. 
$45+15 = 60$, thus, the big square is the unit square, its side is $60$.
Thus, the length of the initial square is equal to $60-30=30$.
\begin{figure}[htb]
\begin{center}
       \includegraphics[scale=0.4]{FiguresArithmetic/tabletteMesopotamie}
\caption{Solving $x^2 + x = 45$.}
\label{fig:equationBabillon}
\end{center}
\end{figure}
*****************************}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\section*{Exercises: Chapter 6}

\begin{itemize}
\item
{\bf 6.4. Evaluating $S_1(n) = \sum_{i=1}^n \ i$, using the fact that $S_2(n) = \sum_{i=1}^n \ i^2$}
\smallskip

{\em Show how to use this machine in order to compute the sum of the first $n$ integers.}

\medskip
The idea here is to write the sum by extracting the two extreme terms of the sum of squares at rank $n+1$ (namely, first and the last element).

\begin{eqnarray*}
S_2(n+1) & = &  \sum_{i=1}^{n} i^2 \ + \ (n+1)^2  \\
 & = & S_2(n) \ + \ (n+1)^2 \\
S_2(n+1) & = &  1 \ + \sum_{i=2}^{n+1} i^2 \\
 & = &  1 \ + \sum_{i=1}^{n} \ (i+1)^2 \\
 & = &  1 \ + \sum_{i=1}^{n} \ (i^2 \ + \ 2.i \ + \ 1) \\
 & = & 1 \ + \ S_2(n) \ + \ 2.S_1(n) \ + n
\end{eqnarray*} 
The term $S_2(n)$ disappears while considering both expressions of $S_2(n+1)$:
\begin{eqnarray*}
 S_2(n) \ + \ (n+1)^2 & = & 1 \ + \ S_2(n) \ + \ 2.S_1(n) \ + n \\
 (n+1)^2 & = & 1 \ + \ 2.S_1(n) \ + n \\
 2.S_1(n) & = & (n+1)^2 \ - \ (n + 1) \\
 S_1(n) & =  & \frac{1}{2} \ n(n+1) 
\end{eqnarray*} 
\medskip

\item
{\bf 6.6. Evaluating a geometric summation pictorially}

In Section~\ref{sec:summing-geometric-series:techniques}, we used Thales's theorem about similarity in triangles (Theorem~\ref{thm:Thm-of-Thales-similarity}) to sum the simple infinite geometric series $\sum_{i=0}^\infty \ b^i$.  It turns out that a modest modification of that evaluation strategy allows us also to evaluate the truncated versions of that series, namely, the summations
\[ S^{(b)}(n) \ = \ \sum_{i=0}^n \ b^i \]

{\em Use the following figure to evaluate $S^{(b)}(n)$.}

\centerline{\includegraphics[scale=0.4]{FiguresArithmetic/ThalesGeometricSumFiniteSol}}
\medskip

\item
{\bf 6.7. A direct proof that the harmonic series diverges}

{\em Develop a proof of the divergence of the harmonic series 
\[ S^{(H)} \ = \ \sum_{k=1}^\infty \ {1 \over k} \]
\begin{itemize}
\item
partitioning $S^{(H)}$'s terms into groups whose sizes are successive powers of $2$
\item
developing an argument based on the sums within the groups.
\end{itemize}
}

\smallskip

The partitioning step operates as follows:
{\footnotesize
\[ 
\begin{array}{ll}
S^{(H)}   & = \ 1  + {1 \over 2} + \left(  {1 \over 3}   +  {1 \over 4}  \right) + \left( {1 \over 5} + {1 \over 6}+ {1 \over 7}  +  {1 \over 8} \right) + \left( {1 \over 9} + {1 \over 10}+ {1 \over 11}  +{1 \over 12} + {1 \over 13} + {1 \over 14} + {1 \over 15} + {1 \over 16} \right) \ +\cdots
\end{array} \]
}

More precisely, each group, say $G_i$, is composed by the $i$ integers from $\frac{1}{2^{(i-1)}+1}$ to $\frac{1}{2^{i}}$ 
(for $i \geq 1$).
Grouping the terms like before, the sum within each group $G_i$ is greater than $\frac{1}{2}$:
\[ 
\begin{array}{l}
{1 \over 3} + {1 \over 4}  > 2.{1 \over 4} = {1 \over 2} \\ \smallskip
{1 \over 5} + {1 \over 6} + {1 \over 7}+ {1 \over 8}  > 4.{1 \over 8} = {1 \over 2}  \\  \smallskip
{1 \over 9} + {1 \over 10} + {1 \over 11}  +{1 \over 12} + {1 \over 13} + {1 \over 14} + {1 \over 15} + {1 \over 16}  > 8.{1 \over 16} = {1 \over 2}  \\  \smallskip
\cdots
\end{array} \]
Thus, 
\[ 
\begin{array}{ll}
S^{(H)} \ > \ 1 \ + \ \left( {1 \over 2} \ + \ {1 \over 2} \right) \ + \left( {1 \over 2} + {1 \over 2} \right) + \cdots
\end{array} \]
\medskip

{\em Propose an alternative analysis by changing the groupings where the terms are gathered 3 by 3}
\[ 
\begin{array}{ll}
S_i & = \left( \frac{1}{3i-1} + \frac{1}{3i} + \frac{1}{3i+1} \right) 
\end{array} \]
\[ 
\begin{array}{ll}
S^{(H)}  & = 1 + S_1 +  \cdots + S_i +  > 1 + 3.\frac{1}{3} + 3.\frac{1}{6} + \cdots + 3.\frac{1}{3i} + \cdots
\end{array} \]

$H = 1 + S_1 +  \cdots + S_i +  \cdots > 1 + 3.\frac{1}{3} + 3.\frac{1}{6} +  \cdots + 3.\frac{1}{3k} + \cdots$

since $S_i > 3.\frac{1}{i} $.

The proof is by contradiction:
if $H$ is finite, from the previous relation we have: $H > 1 + H$, which is obviously impossible.
\medskip

\item
{\bf 6.8. Summations, and summations of summations}
\smallskip

  \begin{itemize}
  \item 1.
{\em Prove that}
\[ \widehat{\Theta}_n \ \eqdef \  \sum_{k=1}^n \ \Delta_k \ = \   
\Delta_1 + \Delta_2 + \cdots + \Delta_n \ = \ \frac{1}{3} \Delta_n \cdot (n+2) \]

%  \item
%{\em Develop and verify a formula for the summation:}
%\[ \Upsilon_n  \ \eqdef \  \sum_{k=1}^n \ \widehat{T}_k \ = \  
%\widehat{T}_1 + \widehat{T}_2 + \cdots + \widehat{T}_n \]

  \item 3.
{\em Prove the following identities involving $\Delta_n$.  For all $n \in \N^+$:}
    \begin{itemize}
    \item a.
$\Delta_n \ + \ \Delta_{n-1} \ = \ n^2$

\smallskip

This is a straightforward exercise in algebraic manipulation.  Can you {\em also} find an ``interesting" proof of this identity, say one that employs a ``pictorial" representation of $\Delta_n$?

 \item b.
$\Delta_n^2 \ - \ \Delta_{n-1}^2 \ = \ n^3$

\smallskip

A simple manipulations of the equation 
\[ \Delta_n \ = \ n \ + \ \Delta_{n-1} \]
provides the solution:

to complete
   \end{itemize}

  \item 4.
{\em Derive a closed-form expression for the sum}
\[ \widehat{\Theta}_n \ + \ \widehat{\Theta} _{n-1} \]

\smallskip

Recall that the sums $\widehat{\Theta}_i$ are defined as sums of $\Delta_j$.  
\end{itemize}
\end{itemize} 


\ignore{*****************************
%%%
\subsection{Sum of perfect cubes}

\noindent \textit{The problem.}
Show that the sum of $n$ first cubes is equal to a perfect square, and more precisely, $\Delta_n^2$.
\medskip

\noindent \textit{The solution.}
The proof is based on an hold and simple pattern that we learned in elementary school.
\medskip

\index{$n^2$ as sum of first $n$ odd integers!a proof from elementary school}

%
Consider the following reasoning which emerges from the way
multiplication tables are developed in elementary school.  
Let us first illustrate the idea using the case $n=5$.
\begin{equation}
\label{eq:Fubini-table}
\begin{array}{rrrrr}
1  &  2 &  3 &  4 &  5 \\
2  &  4 &  6 &  8 & 10 \\
3  &  6 &  9 & 12 & 15 \\
4  &  8 & 12 & 16 & 20 \\
5  & 10 & 15 & 20 & 25 \\
\end{array}
\end{equation}
Write the integers $1, 2, \ldots, n$ in a row.  Below this row, write
the doubles of these integers.  Below the ``double'' row, write the
triples of the integers.  Below the ``triple'' row, write the
quadruples of the integers, then the quintuples, and so on.  Note that
the resulting table is {\em symmetric:} its rows are identical to its
columns.
\medskip

Using again Fubini's rearrangement stratagem, we now count all the integers in
the table in two different ways.
\begin{enumerate}
\item
We sum the entries of our table by peeling away successively larger
reversed instances of the letter ``$L$'' (as in our earlier
``pictorial'' proof of
Proposition~\ref{thm:squares-odd-integers-Gauss}).  We find that the
integers in each ``$L$'' sum to a perfect cube.
Actually, the diagonal is (by definition) equals to the square.
\[
\begin{array}{rrrrrrrrr|rrc}
1  &    &    &    &    &   &     &    &   & 1   & = 1^3 \\
2  &  4 &  2 &    &    &   &     &    &   & 8   & = 2^3 \\
3  &  6 &  9 &  6 &  3 &   &     &    &   & 27  & = 3^3 \\
4  &  8 & 12 & 16 & 12 &  8 &  4 &    &   & 64  & = 4^3 \\
5  & 10 & 15 & 20 & 25 & 20 & 15 & 10 & 5 & 125 & = 5^3
\end{array}
\]

\item
We sum the successive rows of the $n \times n$ table (\ref{eq:Fubini-table}).  
The first row of the table sums to $\Delta_n$; the second row sums to $2
\Delta_n$; the third row sums to $3 \Delta_n$; \ldots; the last row sums
to $n \Delta_n$.  
Thus, the aggregate sum of the table's rows is 
\[ (1 + 2 + \cdots + n) \cdot \Delta_n \ = \ \left(\Delta_n \right)^2 \]
\end{enumerate}
We conclude that
\[
\sum_{i=1}^n i^3 \ = \  \left(\Delta_n \right)^2
\]
************************************************}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\section*{Exercises: Chapter 7}


\ignore{****************************
\subsection{Handling asymptotic}


\noindent \textit{The problem.}

Prove that $f = O(g)$ and $h = O(k)$ for functions $f,g,h,k$ implies that
$f+h = O(g+k)$


\subsection{What's wrong?}

\noindent \textit{The aim.}
to investigate a proof which leads to surprising results.


\begin{enumerate}
\item
Let consider the infinite sum $A = 1-1+1-1+ \ldots$

show that $A=\frac{1}{2}$ (hint: compute $1-A$)
\item
Let now consider the other infinite sum $B=2-3+4-5+6 \ldots$

show that $B=\frac{1}{4}$ (hint: compute $A+B-1$)
\item 
Compute the sum of the integers $C=1+2+3+4+ \ldots$

show that $C=-\frac{1}{12}$ (hint: compute $C-B=4+8+12+16+ \ldots$)
\end{enumerate}

\medskip

\noindent \textit{The problem.}

What's wrong?

\medskip

\noindent \textit{The solution.}
First, summing up positive number should be positive, 
and second, the sum of the integers should be infinite...

Then, how to analyze the previous result/proof?
******************************************************}




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%\section*{Exercises: Chapter 8}

\begin{itemize}

\item
{\bf 8.2. Discovering fractal-like structure in Pascal's triangle}

\ignore{************************
Modular arithmetic can do wondrous, unexpected things with regular structures.  If one takes a system whose structure is governed by arithmetic and substitutes {\em modular} arithmetic for ordinary arithmetic, then the system's structure is somehow going to be ``folded into itself".  We illustrate this fact within a rather complex framework in Appendix~\ref{Appendix:tree-DB}; the ``folded" structures there are trees.  We illustrate the fact within a rather elementary framework in this exercise; the ``folded" structures here arise from Pascal's triangle.

\medskip
*************************}

The Pascal's triangle modulo a prime $m$ (where each of the triangle's entries are taken modulo $m$) is illustrated in Fig.~\ref{fig:TriangleFractal},
%Figs.~\ref{fig:TriangleModulo5raw} and~\ref{fig:TriangleModulo5shade}.
\begin{figure}[ht]
\begin{center}
	\includegraphics[scale=0.3]{FiguresArithmetic/PascalTriangleFractal.png}
	        \caption{The reproducible patterns in Pascal's triangle modulo $5$.
	        the shaded reversed triangles correspond to the input $0$.}
        \label{fig:TriangleFractal}
\end{center}
\end{figure}
a wondrous transformation happens.  The first $m$ levels of the triangle get replicated endlessly, with an inverted $(m-1)$-level triangle whose entries are all $0$.  (In the figure, the inverted triangle of $0$s is depicted in gray.) 
The original triangle has been transformed into a fractal-like repetitive structure whose pattern of repetitions is dictated by the parameter $m$.

\medskip

{\em Prove that the described transformation occurs.}

%
\medskip\item
{\bf 8.4. Divisibility among integers: via the Fundamental Theorem of Arithmetic}

  \begin{itemize}
\item
b. {\bf The sieve of Eratosthenes and its implications}

We formulate the sieve as a regimen for labeling integers with their prime factors.  For simplicity, we use the label $\lambda_p$ to identify integers which are multiples of prime $p$.
\medskip

The multiples of $2$, $3$ and $5$ are labeled in the following table:

$\begin{array}{c|c|c|c|c|c|c|c|c|c|c|c|c}
1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 & 11 & 12 & 13 \\
 & \lambda_2 & & \lambda_2 & & \lambda_2 & & \lambda_2 & & \lambda_2 & & \lambda_2 & \\
 & & \lambda_3 & &  & \lambda_3 & & & \lambda_3 & & & \lambda_3 & \\
 & & & & \lambda_5 & & & & & \lambda_5 & & & 
\end{array}$ \ldots

\bigskip

{\em Prove the following results.}
     \begin{enumerate}
     \item
{\em 
Every integer $n>1$ is divisible by at least one prime number.
}

     \medskip\item
{\em 
Every sequence $k+1, \ldots, k+p$ of $p$ integers contains a multiple of $p$.
}

      \medskip\item This result calls for ``second-order" insights from the sieve.
{\em 
Every product of four consecutive integers, $(k+1) \cdot (k+2) \cdot (k+3) \cdot (k+4)$ is divisible by $4!$
}

\smallskip

{\em Hint}:  Look at the {\em multiplicity} with which a given prime divides a given number, particularly within the context of the spacings of the divisibilities---e.g., every even number that is $2 \times$ an odd number is followed by an even number that is $2 \times$ an even number.  

\smallskip

{\em Extend this exercise to divisors other than $4$.}

\medskip\item
The sieve affords us an alternative proof that there are infinitely many primes, particularly via the alternative version that is due to Leonhard Euler.  In this version of the sieve, each prime and all of its multiples are removed from the sieve as soon as their existence is acknowledged.  Our earlier construction of Eratosthenes's version of the sieve now becomes:

\medskip

$\begin{array}{|l||c|c|c|c|c|c|c|c|c|c|c|c|c|c|}
\hline
\mbox{Initial array:} &
1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 & 11 & 12 & 13 & \cdots \\
\mbox{after prime $2$ is processed:} &
1 &  & 3 &  & 5 &  & 7 &  & 9 &  & 11 &  & 13 & \cdots \\
\mbox{after primes $2, 3$ are processed:} &
1 &  &  &  & 5 &  & 7 &  &  &  & 11 &  & 13 & \cdots \\
\mbox{after primes $2, 3, 5$ are processed:} &
1 &  &  &  &  &  & 7 &  &  &  & 11 &  & 13 & \cdots \\
\hspace*{.8in} \vdots  &
 &  &  &  &  &  & \vdots &  &  &  &  &  &  & \\
\hline
\end{array}$

\bigskip

{\em Use Euler's sieve to prove that there are infinitely many primes.}
\medskip

{\em Hint:} If there were only finitely many primes, then at some (finite) stage in processing the sieve, the list of integers would be reduced to the single integer $1$.
\end{enumerate}
\end{itemize}

 \medskip\item

{\bf 8.5. The ``density"  of divisible pairs of numbers}

{\em Prove that the following assertion is true for every positive integer $n$.}
\medskip

{\em 
For every positive integer $n$:  If you remove {\em any} $n+1$ integers from the set $S = \{ 1, 2, \ldots, 2n\}$, then the set of removed integers contains at least one pair $p$ and $q > p$ such that $p$ divides $q$.
}
\medskip

Let $\alpha_i$ be the elements of this set of $n+1$ elements.
Write $\alpha_i = 2^k \times m$ where $m$ is odd (and $k \geq 0$).

The $2n$ numbers of the sequence are decomposed into multiples of powers of $2$.
When there are multiple ways, we take the one with the largest power of $2$ in order to make the decomposition unique.
Example for $n=7$:

1, 3, 5, 7, 9, 11, 13

2, 6, 10, 14

4, 12

8
\medskip


%The sketch of the proof is as follows.
\begin{enumerate}
\item
 $\alpha_i = 2^k \times m$ 
 
$m$ belongs to the $n$ numbers $\{1,3,5, \ldots, 2n-1 \}$

As we are considering $n+1$ integers, from the pigeon hole principle, there are two numbers with the same value of $m$. 
\item 
Thus, $2^{k1} \times m$ and $2^{k2} \times m$

$p$ is the smallest one, which divides $q$ (the largest one).
\end{enumerate}


\medskip\item

{\bf 8.8. The set $\Q$ of rational numbers is countable}

{\em Prove Proposition~\ref{thm:|Q|=|N|}: $|\Q| \ = \ |\N|$}

\smallskip

Begin by reviewing Proposition~\ref{thm:|NxN|=|N|}, which asserts the technically simpler proposition: $|\N \times \N| \ = \ |\N|$.  What is the relevance of that result to this problem?

\end{itemize}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\section{Chapter 9}

\begin{itemize}
\item
{\bf 9.3. An unusual comparison of automobile brands.}
\smallskip

\ignore{****************************
The logos of two German automakers, {\sc Mercedes}$^{\mbox{\tiny\sc tm}}$ and BMW$^{\mbox{\tiny\sc tm}}$ suggest a (frivolous) game whose analysis can enhance one's understanding of both recurrences and asymptotics.  The game is designed around the fact that the {\sc Mercedes}$^{\mbox{\tiny\sc tm}}$ logo is a {\em trisection} of a circle, while the BMW$^{\mbox{\tiny\sc tm}}$ logo is a {\em quadrisection} of a circle.  
\begin{figure}[htb]
\begin{center}
        \includegraphics[scale=0.3]{FiguresMaths/AutomotiveBrands.png}
\end{center}
\caption{Idealized renditions of the logos on {\sc Mercedes}$^{\mbox{\tiny\sc tm}}$ (left) and BMW$^{\mbox{\tiny\sc tm}}$ (right) automobiles.}
\label{fig:auto-logos}
\end{figure}
The single-player {\it Logo game} proceeds as follows.  

\smallskip

Reflecting the fact that the {\sc Mercedes}$^{\mbox{\tiny\sc tm}}$ logo partitions the circle into {\em three} wedges, while the BMW$^{\mbox{\tiny\sc tm}}$ logo partitions the circle into {\em four} wedges, we assign the player---who, note, has not yet acted---with the initial scores
\[ M(0) \ = \ 3 \ \ \ \ \ \mbox{ and } \ \ \ \ \ B(0) = 4 \] 
and we designate the logo-circles in Fig.~\ref{fig:auto-logos} as the {\em stage-$0$} logo-circles.{\em Note that it is the {\em number} of wedges in each logo-circle that interests us, not the sizes of the wedges}.

The player now becomes active---
\medskip
************************************}

For each positive integer $k$, the player begins at the northernmost point of each stage-$(k-1)$ logo-circle and circumnavigates the circle in a clockwise sense.  In the course of this circumnavigation, the player {\em bisects every second wedge} that she encounters.  When the player regains the northernmost point of the two logo-circles, the numbers of wedges at that moment is recorded as the score at that moment, namely, the pair: at stage $k$ this has the form $\langle M(k), \ B(k) \rangle$. 
\medskip

{\em Prove the following assertions about the described game.}
\begin{itemize}
\item 3.
The asymptotic behavior of $B(n)$ is given by
\[ B(n) \ = \ \left({3 \over 2}\right)^{O(n)} \]
\end{itemize}



\medskip \item
{\bf 9.4. Karatsuba multiplication} 
\smallskip

\ignore{**************************
\index{Karatsuba multiplication algorithm} \index{Karatsuba, Anatoly} 
\index{Karatsuba multiplication}

{\sc Lesson:}
Use the Master Theorem for Linear Recurrences (Theorem~\ref{thm:master-thm-genl}) to analyze a recursive algorithm

\smallskip

Say that you are given two $n$-bit integers, in terms of their base-$2$ numerals: 
\[ A \ = \ a_{n-1} a_{n-2} \cdots a_0 \ \ \ \ \mbox{ and } \ \ \ \ B \ = \ b_{n-1} b_{n-2} \cdots b_0 \]
The classical elementary-school method for computing the product of $A$ and $B$ computes the $n$ partial products:
\[ (a_{n-1} a_{n-2} \cdots a_0) \times b_i 2^i \]
and then sums these partial products.  This algorithm requires $\Theta(n^2)$ multiplications and a like number of additions.

\smallskip

Now, multiplications are more expensive than additions on standard computing platforms.  Therefore, when the common length $n$ of the numerals for $A$ and $B$, is {\em very} large, then one would be willing to perform somewhat more additions (while staying within the asymptotic class $\Theta(n^2)$) if, in compensation, one could save a significant number of multiplications.  Happily, such a tradeoff is, indeed, available, using an algorithm that is known as {\it Karatsuba multiplication}, after its author, Anatoly Karatsuba; see \cite{KaratsubaO62}.

\medskip

Karatsuba's algorithm builds upon the {\it divide-and-conquer} algorithmic paradigm, whereby a
problem {\bf P} is decomposed into disjoint, equal-``size" subproblems whose results are accumulated to solve {\bf P}.
**************************}


\textit{Karatsuba's algorithm.}
Let us return to the problem of multiplying the $n$-bit numerals $A$ and $B$.  To simplify both notation and analysis, say that $n$ is a very large power of $2$, i.e., $n=2^k$ for some large $k \in \N^+$.

\smallskip

The algorithm breaks the numerals for $A$ and $B$ into pairs of half-size numerals:
\begin{eqnarray*}
A & = & A_1 \cdot 2^{n/2} \ + \ A_2 \ \ 
 \eqdef  \ \ (a_n \cdots a_{n/2+1})_2 \cdot 2^{n/2} \ + \ (a_{n/2} \cdots a_1)_2 \\
B & = & B_1 \cdot 2^{n/2} \ + \  B_2 \ \
  \eqdef  \ \ (b_n \cdots b_{n/2+1})_2 \cdot 2^{n/2} \ + \ (b_{n/2} \cdots b_1)_2
\end{eqnarray*}

After this decomposition, we have\footnote{To enhance legibility, we use both the centered dot ($\cdot$) and the multiplication sign ($\times$).}
\begin{equation}
\label{eq:karatsuba-normal}
A \times B \ = \ (A_1 \times B_1) \cdot 2^n \ + \  (A_1 \times B_2 \ + \ A_2 \times B_1) \cdot 2^{n/2} \ + \ (A_2 \times B_2)
\end{equation}
A recursion (on $n$) that is based on instantiating Eq.~(\ref{eq:karatsuba-normal}) employs {\em four} multiplications at this level.

\smallskip

The way that Karatsuba brought the cost of multiplying $A \times B$ below the obvious measure of $\Theta(n^2)$ multiplications was to observe the following.  If one defines
\[ C \ \eqdef \ (A_1 - A_2) \times (B_2 - B_1) \]
then
\begin{eqnarray*}
A \times B & = & (A_1 \times B_1) \cdot 2^n \ + \ (A_2 \times B_2) \\
                 &    & + \ \big(C \ + \ (A_1 \times B_1) \ + \ (A_2 \times B_2) \big) \cdot 2^{n/2}
\end{eqnarray*}

{\em One thereby executes this level of the recursion that computes $A \times B$ using only {\em three} multiplications, rather than the four multiplications in Eq.~(\ref{eq:karatsuba-normal}).}  (The few more additions are often a beneficial cost-tradeoff.)

\medskip

{\em Prove the following assertions.}
\begin{itemize}
\item 2.
{\em A recursion (on $n$) that is based on Karatsuba's algorithm computes the product $A \times B$ using a {\em symptotically fewer than} $\Theta(n^2)$ multiplications.}
\smallskip

Your argument should find a (real) number $\alpha < 2$ such that Karatsuba's algorithm computes the product $A \times B$ using $\Theta(n^\alpha)$ multiplications.
\end{itemize}

\ignore{*************************
\noindent \textit{The solution.}

The relation is easy to check and it is left to the reader. 
Let us use it and replace in the original expression:

$A.B = (A_1.B_1) 2^n + (A_1.B_1 + A_2.B_2 + (A_1-A_2).(B_2-B_1)) 2^{n/2} + A_2.B_2$

The cost analysis is 3 multiplications of $n/2$ bits,
4 additions and 2 subtractions of integers at most $2n$ bits. 

Again, using the Master Theorem leads to:

$T(n) = 3.T(n/2) + \Theta (n) = 3^{\log_2 n} = n^{\log_2 3}$
********************************}

\end{itemize}


%
%\subsection{Solving a bilinear recurrence by a linear system}
%
%\noindent 
%The goal here is to determine the values of  $U_n$
%
%Solve $U_{n} = \frac{1}{2}.U_{n-1} + \frac{1}{2}.U_{n+1}$
%
%knowing $U_0 = 0$ and $U_N = 1$
%



\ignore{
*****\subsection{Lucas' numbers}

\noindent \textit{The problem.}

Prove the following expression.
 
$F(n+1) = \frac{1}{2} (F(0).L(n) + F(n).L(0))$
\medskip

\noindent \textit{The solution.}
The proof comes from direct arithmetic manipulations:

$2.F(n+1) = F(n+1) +  F(n+1) =  F(n+1) + F(n) + F(n-1)$

$= L(n) + F(n) $

$= F(0).L(n) + F(n).L(0)$
\medskip

\noindent \textit{The problem.}

The previous property can be extended for any $m>1$ as follows:
\medskip

$2.F(n+m) = F(m-1).L(n) + F(n).L(m-1)$
\medskip

\noindent \textit{The solution.}
The proof is by recurrence on $m$ considering any fixed $n$.
\begin{itemize}
\item
The \textbf{basis case} (for $m=1$) is given by the previous proposition.

\item
\textbf{Induction step:} 
Assume the property holds at rank $m > 1$ and consider $F(n+m+1)$:

Apply the definition of Fibonacci numbers: 

$F(n+m+1) = F(n+m)+F(n+m-1)$ 

Replace both terms by the recurrence hypothesis:

$= \frac{1}{2} (F(m-1).L(n) + F(n).L(m-1)) + \frac{1}{2} (F(m-2).L(n) + F(n).L(m-2))$

$= \frac{1}{2} \left( (F(m-1)+F(m-2)).L(n) + F(n).(L(m-1)+L(m-2))\right)$

$= \frac{1}{2} \left(F(m).L(n) + F(n).(L(m)\right)$
\end{itemize}
***** }

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\section*{Exercises: Chapter 10}

\begin{itemize}

\ignore{***************************************
\subsection{The average length of a carry in a binary counter}

\noindent {\it The problem.}
%
You add from $1$ to $n$, in increments of $1$ using a counter of
binary (or, base-$2$) numerals.  Each time you increment the counter,
there is a {\it carry}.  These carries have varying lengths; for
instance, when $n = 32 = 100000_2$, the carry-lengths range
from $0$---whenever you increment an even integer---to $5$---when you
increment $31 = 11111_2$ to achieve $32 = 100000_2$. \\
{\em Prove that the average carry as you go from $1$ to $n$ has length $2$.}
\medskip

\noindent {\it The solution.}

\noindent
Half of the increments add $1$ to an even number, i.e., a number whose
binary numeral ends in ``$ \ldots 0$''.  These increments generate no
carry---or, equivalently, a carry of length $0$.

\noindent
One-quarter of the increments, which form half of the remaining
increments, execute a carry of length $1$, because they add $1$ to a
numeral that ends in ``$ \ldots 01$''.

\noindent
One-eighth of the increments, which form half of the remaining
increments, execute a carry of length $2$, because they add $1$ to a
numeral that ends in ``$ \ldots 011$''.

Continuing in this way, one can show that the average length of a
carry can be expressed in the form
\[ 
\frac{1}{2} \cdot 0 \ + \ \frac{1}{4} \cdot 1 \ + \ \frac{1}{8} \cdot
3 \ + \ \frac{1}{16} \cdot 4 \ + \ \cdots
\]
Using techniques that we cover in Chapter~\ref{ch:Summation}, one
verifies that this infinite series converges with the sum $2$.  \qed
********************************}

\item
{\bf 10.3. The Josephus Problem}
\medskip

{\em The aim of this exercise is to determine the survivor $J(n)$ as a function of $n$.}
\medskip


\smallskip   

The process's early erasures, depicted in Fig~\ref{fig:josephus12step1}, should help you start your solution for $J(n)$.
\begin{figure}[ht]
\begin{center}
        \includegraphics[scale=0.35]{FiguresMaths/josephus12step1}
        \hspace*{.2in}
        \includegraphics[scale=0.35]{FiguresMaths/josephus13}
\caption{(Left) First round of the Josephus erasure procedure for $n=12$.
(Right) First two rounds of the procedure when $n=13$; the first round is depicted by solid lines, the second by dotted lines. In both figures, the encircled integers are the ones that have been removed.}
        \label{fig:josephus12step1}  \label{fig:josephus13}
\end{center}
\end{figure}

The following sequence of results provide a roadmap to the solution.

\medskip

We analyze \textit{rounds} of the process---sequences of elementary steps that return to the initial position, $1$.  If position $1$ has been erased, then its role is assumed by the then-smallest survivor.

\smallskip

Easily, the first round of the process takes $\lceil n/2 \rceil$ steps.  Each subsequent round then takes a number of steps that is ``half" the number of its preceding round.  We place ``half" in quotes to emphasize the required up-rounding of each halving.  

\medskip

Fig.~\ref{fig:josephus12step2}, which describes the final rounds of the process, lends intuition for the number of rounds before $J(n)$ stands alone.
\begin{figure}[ht]
\begin{center}
        \includegraphics[scale=0.25]{FiguresMaths/josephus12LastSteps}
        \caption{The final rounds of the Josephus erasure process when $n=12$.}
        \label{fig:josephus12step2}
\end{center}
\end{figure}

\medskip

The following quadripartite proposition now leads to the solution.

{\em 
The value of $J(n)$, as determined by $n$:

\begin{tabular}{clll}
 & \underline{Condition on $n$} & \hspace*{.1in} & \underline{Value of $J(n)$} \\ 
{\bf (a)} &
For all $n$ &  & $J(n)$ is odd. \\
{\bf (b)} &
$n$ is even; i.e., $n = 2m$ & & $J(2m) \ = \ 2J(m)-1$ \\
{\bf (c)} &
$n$ is odd; i.e., $n = 2m+1$ & & $J(2m+1) = 2J(m)+1$ \\
{\bf (d)} &
$n = 2^m+k$, with $k < 2^m$ & & $J(2^m+k) = 2k+1$
\end{tabular}
}

\fbox{\em Your quadripartite proof is needed here.}

\begin{proof}
This is a simple generalization of the previous proposition.  If $n$ is even, then the first round corresponds simply to come back to the original circle where one half of the points have been removed. 
\end{proof}

Next, grouping values of $n$ between successive powers of $2$, we find that

Let $n=2^m+k$, the rule within each group $m$ is to start at $1$ and increase by $2$ the successive numbers
($0 \leq k < 2^m$).
Let prove it by recurrence on $n$.
\medskip

\begin{prop}
For all $n = 2^m+k$, where $k < 2^m$, we have
$J(2^m+k) = 2k+1$.
\end{prop}

\begin{proof}
\begin{itemize}
\item {\bf Basis.} 
$n=1$, thus $m=0$, $k=0$ and $J(1) = 2^0+0 = 1$
\medskip\item {\bf Induction step.} 
Suppose the formula holds for any integer lower than $n=2^m+k$. 
Since there are two expressions for $J(.)$, we distinguish the cases whether $k$ is even or it is odd:
\begin{itemize}
\item If $k$ is even, then, $2^m+k$ is even, and we can write:

$J(2^m+k) = 2J(2^{m-1}+\frac{k}{2})-1$

by induction hypothesis, $J(2^{m-1} +\frac{k}{2}) = 2\frac{k}{2} +1 = k+1$

Thus, $J(2^m+k) = 2(k+1) -1 = 2k+1$.

\medskip\item If $k$ is odd, the proof is similar:

$J(2^m+k) = 2J(2^{m-1}+\lfloor \frac{k}{2} \rfloor)+1 = 2\lfloor \frac{k}{2} \rfloor +1 = 2k+1$.

\end{itemize}
\end{itemize}
\end{proof}

\medskip

Your ultimate solution for $J(n)$ will emerge from analyzing what the preceding propositions yield as the value of $J(n)$.  

\smallskip

\fbox{\em Provide a closed-form expression for $J(n)$ in terms of $n$'s base-$2$ numeral.}

\medskip

{\em Hint.}
Consider the binary {\em numerals} for $n = 2^m +k$ and $k$.  We first note that, {\em numerically},
\begin{eqnarray*}
n & = &  2^m b_m \ + \ 2^{m-1} b_{m-1} \ + \cdots + \ 2 b_1 \ + \ b_0 \\
k & = & 2^{m-1}  b_{m-1} \ + \cdots + \ 2 b_1 \ + \ b_0
\end{eqnarray*} 
where each bit $b_i \in \{0,1\}$.  Therefore, in terms of {\em base-$2$ numerals}:
\[ \begin{array}{ccrl}
(n)_2 & = & 1 b_{m-1} \cdots b_1 b_0 & (\mbox{by definition, } \ b_m=1) \\ 
(k)_2 & = & 0 b_{m-1} \cdots b_1 b_0 & (\mbox{because } [n = 2^m +k] \ \mbox{ and } \ k < 2^m)
\end{array}
\]

\[ (J(n))_2 \ = \ b_{m-1} \cdots b_0 b_m. \]
which indicates that $J(43) = 23$.  The pictorial interpretation of this coding is given in Fig.~\ref{fig:josephusCoding} for $n=43$.
\begin{figure}[h]
\begin{center}
        \includegraphics[scale=0.4]{FiguresMaths/josephusCoding}
        \caption{Obtaining the survivor number $J(43)$.}
        \label{fig:josephusCoding}
\end{center}
\end{figure}

The figure indicates that the solution for $J(n)$ is obtained by a simple shift of the binary representation of $n$.

%%%

\medskip\item
{\bf 10.5. An alternative to Horner's Rule}

{\sc Lesson:} Experience with operation-counting and asymptotics

\smallskip

In Section~\ref{sec:Horner-fast-evaluation}, we described Horner's Rule, a method for calculating polynomials faster than the common way of writing polynomials would suggest.  This exercise is devoted to an alternative streamlined polynomial evaluation procedure, called {\it Estrin's method}, after its inventor, Gerald Estrin \cite{Estrin60}.

\index{Estrin, Gerald} \index{Estrin's method (for evaluating univariate polynomials)}

\smallskip

Estrin's method begins with a polynomial of degree $d$ with real coefficients:
\[
P(x) \ \ = \ \ a_0 \ + \ a_1 x \ + \ a_2 x^2 \ + \cdots + \ a_{d-1} x^{d-1} \ + \ a_d x^d
\]
To avoid complicated expressions, we apply the method to the degree-$(d=7)$ polynomial:
\[
P_7(x) \ \ = \ \ a_0 \ + \ a_1 x \ + \ a_2 x^2 \ + \ a_3 x^3 \ + \ a_4 x^4 \ + \ a_5 x^5 \ + \ a_6 x^6 \ + \ a_7 x^7
\]

\smallskip

We begin by rewriting $P$ as follows, via repeated factorizations.
\[
P(x) \ \ = \ \ a_0 \ + \ x \cdot (a_1 \ + \ x \cdot (a_2  \ +  \cdots                                          
+ x \cdot (a_{d-2} \ + \ x \cdot (a_{d-1} \ + \ a_d x)) \cdots ))
\]
Applied to $P_7(x)$, this rewriting yields:
\[
P_7(x) \ \ = \ \ a_0 \ + \ a_1 x \ + \ x^2 \ ( a_2  \ + a_3 x \ ) \ + \ x^4 \ ( \ a_4 \ + \ a_5 x \ + \ x^2 \ ( a_6  \ + a_7 x \ ) \ )
\]
We then introduce the recursively auxiliary expressions.  
\begin{eqnarray*}
C_i^{(0)} & = & a_i + x a_{i+1} \\
                &\vdots &  \\
C_i^{(n)}  & = & C_i^{(n-1)} + x^{2n} C_{i+2^n}^{(n-1)}
\end{eqnarray*}
The method completes by expressing $P(x)$ in terms of the auxiliary $C_i^{(k)}$

\smallskip

Example:
\begin{eqnarray*}
P_7(x) & = & C_{0}^{(0)} \ + \ x^2 \ C_2^{(0)} \ + \ x^4 \ ( \ C_4^{(0)} \ + \ x^2 \ C_6^{(0} \ ) \\
            & = & C_0^{(1)} \ + \ x^4 \ C_4^{(1)}
\end{eqnarray*}

\medskip

{\em To do:}
\begin{enumerate}
\item
{\em Write $P(x)$ using the auxiliary expressions $C_i$.}  {\em To simplify this task, say that the degree $d$ is a power of $2$.}
\medskip\item
{\em Determine how many additions and multiplications are required to evaluate $P(x)$.}
\end{enumerate}
\end{itemize}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \section{Chapter 11}
\begin{itemize}
\item
{\bf 11.2. Counting replicated triangles}
\smallskip

How does the progression of numbers of triangles contained into $T_k$ grow? 
To this end, let $N_i$ denote the number of triangles within triangle $T_k$.  
We have just seen that $N_0 =1$, $N_1 = 5$, and $N_2 = 13$.
  \begin{itemize}
  \item
{\em Compute} $N_4$.
\smallskip

Reasoning on the case $k=4$ will give us hint of the general case.

See Fig.~\ref{fig:countingTriangles}(left).
\begin{figure}[h]
\begin{center}
        \includegraphics[scale=0.35]{FiguresArithmetic/CountingTriangles}
        \caption{The first three stages of triangle-replication.}
        \label{fig:countingTriangles}
\end{center}
\end{figure}

\medskip\item
{\em Develop a recurrence for} $N_k$ (i.e., the general case).
\end{itemize}

%%%


\medskip\item
{\bf 11.6. Monge shuffles: mathematical party tricks}

{\sc Lesson:} Experience with analyzing combinatorial patterns

\smallskip

\index{Monge, Gaspard} \index{Monge shuffle}

We consider two ways of shuffling cards which are associated with the 18-19th century French mathematician Gaspard Monge.  We employ the shuffle-techniques as vehicles for honing your skills in detecting combinatorial patterns.  Others have used them as party tricks.

\smallskip

For both shuffle-techniques. we begin with a deck of $2n$ distinct cards.  We employ the running example of the following small deck, where $n=4$:
\[ (1, \ 2, \ 3, \ 4, \ 5, \ 6, \ 7, \ 8) \]
For both {\it Monge shuffles} of the cards, we cut the deck in the middle, to create two $n$-card decks:
\[ (1, \ 2, \ 3, \ 4), \ (5, \ 6, \ 7, \ 8) \]
We then merge the two $n$-card decks to again obtain a single $2n$-card deck.  The two Monge shuffles differ in their merging techniques.

  \begin{enumerate}
  \item $\oplus$ {\bf The simple Monge shuffle}

\smallskip

The first, simple, Monge shuffle alternates the ``top" cards from the righthand and lefthand $n$-card decks; see Fig~\ref{fig:suffleMonge}.  The merged deck has the form
\[ (5, \ 1, \ 6, \ 2, \ 7, \ 3, \ 8, \ 4) \]
\begin{figure}[h]
\begin{center}
        \includegraphics[scale=0.4]{FiguresArithmetic/suffleMongeBasic}
        \caption{The Monge shuffle for $8$ cards ($n=4$).}
        \label{fig:suffleMonge}
\end{center}
\end{figure}

In the party-game incarnation of the Monge shuffle, you demonstrate the cut-then-merge process of Fig~\ref{fig:suffleMonge}, and you suggest to your audience that this process is a good first step in really mixing up the cards.  If this were so, then repeating the step several times should be a good way to obtain a ``random" mixture of the cards.

\smallskip

Let's see what happens after several steps of this cut-then-merge process:
\[ \begin{array}{ccccccccccccccccc}
(1 & 2 & 3 & 4 & 5 & 6 & 7 & 8) & \rightarrow & (1 & 2 & 3 & 4) & (5 & 6 & 7 & 8) \\
 & & & & & & & & \swarrow & & & & & & & & \\
(5 & 1 & 6 & 2 & 7 & 3 & 8 & 4) & \rightarrow & (5 & 1 & 6 & 2) & (7 & 3 & 8 & 4) \\
 & & & & & & & & \swarrow & & & & & & & & \\
(7 & 5 & 3 & 1 & 8 & 6 & 4 & 2) &  \rightarrow& (7 & 5 & 3 & 1) & (8 & 6 & 4 & 2) \\
 & & & & & & & & \swarrow & & & & & & & & \\
(8 & 7 & 6 & 5 & 4 & 3 & 2 & 1) &  \rightarrow& (8 & 7 & 6 & 5) & (4 & 3 & 2 & 1) \\
 & & & & & & & & \swarrow & & & & & & & & \\
(4 & 8 & 3 & 7 & 2 & 6 & 1 & 5) &  \rightarrow& (4 & 8 & 3 & 7) & (2 & 6 & 1 & 5) \\
 & & & & & & & & \swarrow & & & & & & & & \\
(2 & 4 & 6 & 8 & 1 & 3 & 5 & 7) &  \rightarrow& (2 & 4 & 6 & 8) & (1 & 3 & 5 & 7) \\
 & & & & & & & & \swarrow & & & & & & & & \\
(1 & 2 & 3 & 4 & 5 & 6 & 7 & 8)
\end{array}
\]
So, this does not look too random!  After {\em three} (which, ``coincidentally", equals $n-1$) cut-then-merge steps, the deck has been reversed, and after $2n-1$ cut-and-merge steps, it has been replicated in its original order!
\medskip

{\em Prove the following Proposition.}

Let $p$ be a prime ($p>2$), and let $n = {1 \over 2} (p-1)$.  
Let us begin with a deck of $2n$ distinct cards and perform the simple Monge shuffle on the deck.  
After some number $m$ of cut-then-merge steps, where $m$ divides $p-1$, the simple Monge shuffle replicates the initial deck.
\smallskip

Studying our sample sequence of cut-then-merge steps should provide a valuable hint.

\medskip
\item {\bf The sophisticated Monge shuffle}
\smallskip

We now provide a more sophisticated merge procedure, which yields a sophisticated variant of the Monge shuffle.  In each stage of this variant---each corresponding to a cut-then-merge step of the simple shuffle---we rearrange the $2n$-card deck directly, from the middle outward, via the following regimen:

\smallskip

\noindent
- Card \#1 of the original deck is placed in position $n+1$ of the shuffled deck \\
- Card \#2 of the original deck is placed in position $n$ of the shuffled deck \\
- Card \#3 of the original deck is placed in position $n+2$ of the shuffled deck \\
- Card \#4 of the original deck is placed in position $n-1$ of the shuffled deck \\
\hspace*{.1in} \ldots and so on, until the original deck is empty.

\smallskip
\ignore{********************************
The first few steps of a stage of the sophisticated Monge shuffle are illustrated for the case $n=4$ in Fig.~\ref{fig:suffleMonge1};
\begin{figure}[h]
\begin{center}
        \includegraphics[scale=0.33]{FiguresArithmetic/suffleMongeStep1}
        \includegraphics[scale=0.33]{FiguresArithmetic/suffleMongeStep2}
         \includegraphics[scale=0.33]{FiguresArithmetic/suffleMongeStep3}
        \caption{The Monge shuffle for $8$ cards ($n=4$): Step 1 (left), Step 2 (center), Step 3 (right).}
        \label{fig:suffleMonge1}
\end{center}
\end{figure}
one complete stage is illustrated in the table following the figure.
\[ \begin{array}{cccccccccccccccccc}
\mbox{Step } & \multicolumn{8}{c}{\mbox{Original deck}} & &
     \multicolumn{8}{c}{\mbox{Shuffled deck}} \\
\hline
1 & (1 & 2 & 3 & 4 & 5 & 6 & 7 & 8) & \rightarrow & ( - & - & - & - & 1 & - &  - & - ) \\
2 & ( - & 2 & 3 & 4 & 5 & 6 & 7 & 8) & \rightarrow & ( - & - & - & 2 & 1 & - & - & - ) \\
3 & ( - & - & 3 & 4 & 5 & 6 & 7 & 8) &  \rightarrow& ( - & - & - & 2 & 1 & 3 & - & - ) \\
4 & ( - & - & - & 4 & 5 & 6 & 7 & 8) &  \rightarrow& ( - & - & 4 & 2 & 1 & 3 & - & - ) \\
5 & ( - & - & - & - & 5 & 6 & 7 & 8) &  \rightarrow& ( - & - & 4 & 2 & 1 & 3 & 5 & - ) \\
6 & ( - & - & - & - & - & 6 & 7 & 8) &  \rightarrow& ( - & 6 & 4 & 2 & 1 & 3 & 5 & - ) \\
7 & ( - & - & - & - & - & - & 7 & 8) &  \rightarrow& ( - & 6 & 4 & 2 & 1 & 3 & 5 & 7 ) \\
8 & ( - & - & - & - & - & - & - & 8) &  \rightarrow& ( 8 & 6 & 4 & 2 & 1 & 3 & 5 & 7 ) \\
\end{array}
\]
*********************************}

\medskip

{\em Prove the following Proposition.}

For any integer $n \in \N^+$: 
If $4n+1$ is prime, then performing $2n$ steps of the sophisticated Monge shuffle on a deck of $2n$ distinct cards restores the deck to its original order.
\end{enumerate}
  
\end{itemize}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\section*{Exercises: Chapter 12}

\ignore{******************************************
\subsection{Formal definition of mesh graphs}
\label{Exercice:FormalDefinitionMesh}

\noindent \textit{The problem.}
Formalize precisely the definition of mesh  $\m_{m,n}$ and torus $\widetilde{\m}_{m,n}$ graphs
for positive integers $m, n \in \N^+$.
\medskip

\noindent \textit{The solution.}
The  {\it vertex-set} is the same for both graphs:

\begin{eqnarray*}
\n_{\fm_{m,n}} \ = \ \n_{\widetilde{\fm}_{m,n}}
  & = & 
\{1, \ 2, \ldots, \ m\} \ \times \ \{1, \ 2, \ldots, \ n\} \\
  & = & 
\big\{ \langle i, \ j \rangle \ \ | \ \ 
\big[ i \in \{1, \ 2, \ldots, \ m\} \big], \ \
\big[ j \in \{1, \ 2, \ldots, \ n\} \big]
\big\}
\end{eqnarray*}

$\m_{m,n}$ has $(m-1)n \ + \ (n-1)m$ edges; its {\it edge-set} is
\begin{eqnarray*}
\e_{\fm_{m,n}} & = & 
\big\{
\{ \{ i, j \}, \ \{ i+1, j \} \ \ | \ \
1 \leq i < m, \ \ 1 \leq j \leq n \} \\
  &  & \hspace*{.1in} \cup
\{ \{ i, j \}, \ \{ i, j+1 \} \ \ | \ \
1 \leq i \leq m, \ \ 1 \leq j < n \}
\big\}
\end{eqnarray*}

\medskip

The subgraph of $\m_{m,n}$ defined by the vertex-set
\[ \{ \langle i, \ j \rangle  \ \ | \ \ \left[i \in \{1, 2, \ldots,
  m\}\right], \ \ \left[1 \leq j < n\right]\}
\]
and all edges both of whose endpoints belong to that set is called the
$i$th {\it row} of $\m_{m,n}$
Dually, the subgraph of $\m_{m,n}$ defined by the vertex-set
\[ \{ \langle i, \ j \rangle  \ \ | \ \ \left[j \in \{1, 2, \ldots,
  n\}\right], \ \ \left[1 \leq i < m\right] \}
\]
and all edges both of whose endpoints belong to that set is called the
$j$th {\it column} of $\m_{m,n}$.


\begin{itemize}
     \item
Vertices $\langle 1, \ 1 \rangle$, $\langle 1, \ n \rangle$, $\langle m,
\ 1 \rangle$, and $\langle m, \ n \rangle$ are the {\it corner vertices}
(or, just {\it corners}) of $\m_{m,n}$.
     \item
The path-graph consisting of the vertex-set
\[ \{ \langle 1, \ 1 \rangle, \ \langle 1, \ 2 \rangle, \ldots, \
\langle 1, \ n \rangle \}
\]
together with all edges of $\m_{m,n}$ both of whose endpoints belong
to this set, is the {\it top edge} of $\m_{m,n}$.

The other edges of $\m_n$ are defined analogously:

\medskip

The {\it bottom edge} of $\m_{m,n}$ is the path-graph built upon the
vertex-set
\[ \{ \langle m, \ 1 \rangle, \ \langle m, \ 2 \rangle, \ldots, \
\langle m, \ n \rangle \}
\]

The {\it left edge} of $\m_{m,n}$ is the path-graph built upon the
vertex-set
\[ \{ \langle 1, \ 1 \rangle, \ \langle 2, \ 1 \rangle, \ldots, \
\langle m, \ 1 \rangle \}
\]

The {\it right edge} of $\m_{m,n}$ is the path-graph built upon the
vertex-set
\[ \{ \langle 1, \ n \rangle, \ \langle 2, \ n \rangle, \ldots, \
\langle m, \ n \rangle \}
\]
\end{itemize}
\medskip

Same for the torus graphs:

The subgraph of $\widetilde{\m}_{m,n}$ defined by the vertex-set
\[ \{ \langle i, \ j \rangle  \ \ | \ \ \left[i \in \{1, 2, \ldots,
  m\}\right], \ \ \left[1 \leq j \leq n\right]\}
\]
and all edges both of whose endpoints belong to that set is called the
$i$th {\it row} of $\widetilde{\m}_{m,n}$
Dually, the subgraph of$\widetilde{\m}_{m,n}$ defined by the vertex-set
\[ \{ \langle i, \ j \rangle  \ \ | \ \ \left[j \in \{1, 2, \ldots,
  n\}\right], \ \ \left[1 \leq i \leq m\right] \}
\]
and all edges both of whose endpoints belong to that set is called the
$j$th {\it column} of $\widetilde{\m}_{m,n}$.
%\medskip
%
%\noindent \textit{Lesson learned.}
%manipulate mathematical symbols. 
****************************************}

\begin{itemize}
\item
{\bf 12.1. Vertex-degrees and the existence of paths}
\smallskip

{\em Prove that if every vertex of graph $\g$ has degree $\geq d$, then $\g$ contains a {\em simple} path of length $d$.}

\medskip\item
{\bf 12.2. Vertex-degrees and their distributions in graphs}
\smallskip

{\em Prove the following results.}

\begin{prop}
Let $\g$ be an arbitrary graph.
\smallskip

\noindent
{\bf (a)} The sum of $\g$'s vertex-degrees is even.
\smallskip

\noindent {\bf (b)}
The number of $\g$'s vertices having odd vertex-degree is even.
\end{prop}

\medskip\item
{\bf 12.8. A small graph isomorphism}
\smallskip

{\em Prove the following Proposition:}
\smallskip

{\em The order-$4$ hypercube $\q_4$ is \textit{isomorphic} to the $4 \times 4$ torus $\widetilde{\m}_{4,4}$.}
\smallskip

Try to find a relation (an ``encoding") between the bit-strings that name the vertices of $\q_4$ and the ordered pairs of integers that name the vertices of $\widetilde{\m}_{4,4}$.

\smallskip 

Once you get an idea for how such an ``encoding" might work, try to incorporate the inter-vertex names of edges for both graphs.
\medskip

$\q_4$ is represented by its natural Gray codes,
where a vertex is coded 4 bits and connected to its four neighbors by complementing 
the digit in each of the four dimensions.
See Fig.~\ref{fig:IsomorphismCodingPrinciple} for the correspondence between hypercube and torus for coding a node and its related links.
\medskip
 \begin{figure}[hbt]
\begin{center}
       \includegraphics[scale=0.4]{FiguresGraph/IsomorphismEx2}
       \caption{Coding schemes for the hypercube and torus.}
  \label{fig:IsomorphismCodingPrinciple}
\end{center}
\end{figure}

$\widetilde{\m}_{4,4}$ is the cartesian product between two mono-dimensional rings.
Each one is composed of the four vertices connected using a Gray code:

$00, 01, 11, 10$

The whole coding is obtained by concatenation of both dimensions.
See Fig.~\ref{fig:IsomorphismCodingComplete}
 \begin{figure}[hbt]
\begin{center}
       \includegraphics[scale=0.4]{FiguresGraph/IsomorphismEx1}
       \caption{Complete coding schemes.}
  \label{fig:IsomorphismCodingComplete}
\end{center}
\end{figure}

\medskip\item
{\bf 12.9. A traffic map for a mesh-structured city}
\smallskip

%Here is a {\em highly structured, recursive} proposal for a traffic network.  To simplify our work, let us assume that $N$ has the form $n^2$ with $n = 2^{m}$. 
%  \begin{itemize}
%  \item
%We logically arrange the city's $N$ sites in an $n \times n$ grid by assigning each site a distinct name of the form $\langle i,j \rangle$, where $i, j \in \{1, 2, \ldots, n\}$.
%
%\smallskip
%Fig.~ \ref{fig:routingCity} gives an illustration of the previous textual description.
%\begin{figure}[hbt]
%\begin{center}
%       \includegraphics[scale=0.4]{FiguresGraph/routingCity}
%\caption{A $64$-site city arranged as an $8 \times 8$ grid.  The figure illustrates: the level-$0$ $8 \times 8$ grid and its northwestern $4 \times 4$ quadrant; the grid's four level-$2$ northwestern $2 \times 2$ quadrants (shaded).}
%  \label{fig:routingCity}
%\end{center}
%\end{figure}
%\begin{figure}[hbt]
%\begin{center}
%       \includegraphics[scale=0.3]{FiguresGraph/routingCitySynthesis}
%\caption{Summary of the routing rules.}
%  \label{fig:routingCitySynthesis}
%\end{center}
%\end{figure}
%  \medskip\item
%We turn now to the (oriented) edges that we use to navigate our grid-like city.
%
%\smallskip
%
%We eliminate (from consideration) all ``diagonal" edges.  Phrased positively: we employ only edges whose endpoint-sites share a coordinate.  Each of these edges goes from a site $\langle i,j \rangle$ to a site $\langle i,k \rangle$ or a site $\langle h,j \rangle$.
%
%\smallskip
%
%This means that every {\em oriented} edge now goes either northward or southward or eastward or westward.
%
%\medskip\item
%We now assign (oriented) edges to levels, as a prelude to our routing regimen.
%
%\smallskip
%
%Focus on an edge $e$.  We say that $e$ is a level-$\ell$ edge if $\ell$ is the smallest integer such that the endpoints of $e$ are in distinct level-$\ell$ quadrants.
%
%  \medskip\item
%As the final step in creating our abstract traffic model, we impose the following routing regimen upon the travelers in our city.
%
%\smallskip
%
%In order to travel from site $\langle i,j \rangle$ to site $\langle h,k \rangle$, a traveler:
%    \begin{itemize}
%    \item
%must traverse the at-most three edges that lead site $\langle i,j \rangle$ to some site $\langle i_1,j_1 \rangle$ within the same quadrant as site $\langle h,k \rangle$.
%
%   \medskip\item
%From that point on, the traveler recursively finds an acceptable path from site $\langle i_1,j_1 \rangle$ to site $\langle h,k \rangle$.
%    \end{itemize}
%  \end{itemize}

In both of the sought analyses, the phrase ``worst-case" means that the sites are situated pessimally for our regimen.
  \begin{enumerate}
  \item
In the {\em metro} version of the model, we pay a fee every time we encounter a new site on the way from $\langle i,j \rangle$ to $\langle h,k \rangle$.

\smallskip

{\em What is the cost of a trip from a site $\langle i,j \rangle$ to the most-distant site,$\langle h,k \rangle$, under the \underline{metro} model?}

  \medskip\item
In the {\em driving} version of the model, we pay a per-kilometer fee of $n^{(1/2)^\ell}$ units every time we traverse a level-$\ell$ edge on the way from $\langle i,j \rangle$ to $\langle h,k \rangle$.
 
 \smallskip

{\em What is the cost of a trip from a site $\langle i,j \rangle$ to the most-distant site, $\langle h,k \rangle$, under the \underline{driving} model?}

 \end{enumerate}
 \begin{figure}[hbt]
\begin{center}
       \includegraphics[scale=0.5]{FiguresGraph/routingCitySolution1}
       \caption{To discuss.}
  \label{fig:routingCity}
\end{center}
\end{figure}
 \begin{figure}[hbt]
\begin{center}
       \includegraphics[scale=0.5]{FiguresGraph/routingCity2}
       \caption{To discuss.}
%  \label{fig:routingCity}
\end{center}
\end{figure}
 \begin{figure}[hbt]
\begin{center}
       \includegraphics[scale=0.5]{FiguresGraph/routingCity3}
       \caption{Shortest path.}
%  \label{fig:routingCity}
\end{center}
\end{figure}

\end{itemize}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\section*{Exercises Chapter 13}

\begin{itemize}
\item
{\bf 13.2. Appreciating de Bruijn networks}
\smallskip


\noindent
{\em a. Identify, by coloring the edges of $\d_3$ and $\d_4$, how each network can be viewed as two trees which are ``embracing" one another.}

\smallskip

to be completed


  \medskip\item 
{\bf 13.4. Fundamental insights into outerplanarity in graphs}
\smallskip

{\em Prove the following assertions.}


\noindent {\em a. Show that the complete bipartite graph $K_{3,2}$ is not outerplanar.}
\smallskip

%\begin{figure}[h]
%\begin{center}
%        \includegraphics[scale=0.35]{FiguresGraph/outerplanarK3,2init} 
%\caption{$K_{3,2}$: Its two types of vertices are identified by color---white and shaded.}
%\end{center}
%\end{figure}

The solution is a case by case analysis according to all the possibilities to distribute  $K_{3,2}$'s vertices around a circle.
\begin{figure}[h]
\begin{center}
        \includegraphics[scale=0.4]{FiguresGraph/outerplanarK3,2}
        \caption{The two only possibilities to distribute the white and shaded vertices along a circle.}
\end{center}
\end{figure}


\end{itemize}



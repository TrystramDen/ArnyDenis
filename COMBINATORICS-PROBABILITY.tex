%version of 06-21-18

\chapter{COMBINATORICS, PROBABILITY, AND STATISTICS}
\label{ch:combinatorics}

\section{The Fundamentals of Counting}
\label{sec:counting}


\subsection{Binary Strings and Power Sets}

\begin{prop}
\label{thm:b-ary strings}
For every integer $b > 1$, there are $b^n$ $b$-ary strings of length
$n$.
\end{prop}

\begin{proof}
The asserted numeration follows most simply by noting that there are
always $b$ times as many $b$-ary strings of length $n$ as there are of
length $n-1$.  This is because we can form the set of $b$-ary strings
of length $n$ as follows.  Take the set $A_{n-1}$ of $b$-ary strings
of length $n-1$, and make $b$ copies of it, call them $A^{(0)}_{n-1},
A^{(1)}_{n-1}, \ldots, A^{(b-1)}_{n-1}$.  Now, append $0$ to every
string in $A^{(0)}_{n-1}$, append $1$ to every string in
$A^{(1)}_{n-1}$, \ldots, append $\bar{b} = b-1$ to every string in
$A^{(b-1)}_{n-1}$.  The thus-amended sets $A^{(i)}_{n-1}$ are mutually
disjoint (because of the terminal letters of their respective
strings), and they collectively contain all $b$-ary strings of length
$n$.  \qed
\end{proof}

\medskip

\addcontentsline{toc}{paragraph}{-- A fun result: $n$-element sets
  have $2^n$ subsets}

\begin{prop}
\label{thm:power-sets}
The power set $\p(S)$ of a finite set $S$ contain $2^{|S|}$ elements.
\end{prop}

\begin{proof}
Let us begin by taking an arbitrary finite set $S$---say of $n$
elements---and laying its elements out in a line.  We thereby
establish a correspondence between $S$'s elements and positive
integers: there is the first element, which we associate with the
integer $1$, the second element, which we associate with the integer
$2$, and so on, until the last element along the line gets associated
with the integer $n$.

Next, let's note that we can specify any subset $S'$ of $S$ by
specifying a length-$n$ {\em binary (i.e., base-$2$) string}, i.e., a
string of $0$'s and $1$'s.  The translation is as follows.  If an
element $s$ of $S$ appears in the subset $S'$, then we look at the
integer we have associated with $s$ (via our linearization of $S$),
and we set the corresponding bit-position of our binary string to $1$;
otherwise, we set this bit-position to $0$.  In this way, we get a
distinct subset of $S$ for each distinct binary string, and a distinct
binary string for each distinct subset of $S$.

Let us pause to illustrate our correspondence between sets and strings
by focussing on the set $S = \{a,b,c\}$.  Just to make life more
interesting, let us lay $S$'s elements out in the order $b,a,c$, so
that $b$ has associated integer $1$, $a$ has associated integer $2$,
and $c$ has associated integer $3$.  We depict the elements of $\p(S)$
and the corresponding binary strings in the following table.
\begin{center}
\fbox{
\begin{tabular}{c|c|c}
Binary string & Set of integers & Subset of $S$ \\
\hline
$000$ & $\emptyset$ & $\emptyset$ \\
$001$ & $\{3\}$     & $\{c\}$ \\
$010$ & $\{2\}$     & $\{a\}$ \\
$011$ & $\{2,3\}$   & $\{a,c\}$ \\
$100$ & $\{1\}$     & $\{b\}$ \\
$101$ & $\{1,3\}$   & $\{b,c\}$ \\
$110$ & $\{1,2\}$   & $\{a,b\}$ \\
$111$ & $\{1,2,3\}$ & $\{a,b,c\} =S$
\end{tabular}
}
\end{center}

Back to the Proposition: We have verified the following: {\em The
  number of length-$n$ binary strings is the same as the number of
  elements in the power set of $S$!}  The desired numeration thus
follows by the ($b=2$) instance of Proposition~\ref{thm:b-ary
  strings}.  \qed
\end{proof}

\begin{quote}
The binary string that we have constructed to represent each set of
integers $N \subseteq \{0, 1, \ldots, n-1\}$ is called the {\it
(length-$n$) characteristic vector}\index{characteristic vector}
{\it of the set} $N$.  Of course, the finite set $N$ has
characteristic vectors of all finite lengths.  Generalizing this idea,
{\em every} set of integers $N \subseteq \N$, whether finite or
infinite, has an {\em infinite} characteristic vector, which is formed
in precisely the same way as are finite characteristic vectors, but
now using the set $\N$ as the base set.
\end{quote}


\section{The Elements of Probability}
\label{ch:prob-stat}



 within discrete frameworks, including introducing
discrete probability/likelihood as a ratio:
\[ 
\frac{\mbox{number of targeted events}}{\mbox{number of possible events}}
\]


Elements of probability theory and statistics infuse every area of
computing.  The practicality of many algorithms that are
experientially the most efficient for their target tasks depend on the
{\em distribution} of inputs in ``real" situations.  Design
methodologies for crucial complex circuits must acknowledge the {\em
  mean times to failure} of the critical components of the circuits.
Sophisticated searching algorithms must take into account the relative
{\em likelihoods} of finding one's goal in the various optional search
directions.  Analyzing and understanding large corpora of data
requires a variety of methodologies that build on the concepts of {\em
  clustering} and/or {\em decomposition}.

A student needs at least an introduction to the foundations of
probability and statistics to even understand, all the moreso to
master, the terms highlighted in the preceding paragraph.  We outline
many of the key concepts that a student must be exposed to in the
following subsections.


\subsection{The basicsElements of Combinatorial Probability}

Perhaps the easiest and most engaging way to introduce ``probability
via counting" is by calculating the comparative likelihoods of various
deals in $5$-card poker and of various rolls of a pair of dice.  The
arithmetic required for this discussion is elementary and the
``application" to gambling of interest even to non-gamblers: ``Why is
such a deal in poker (say, a straight) worth more than another (say,
three of a kind)?"  One can also introduce in this setting concepts
such as randomness, bias, etc., that are so important in the design of
experiments and the analysis of their outcomes.

\section{Toward a Basic Understanding of Statistics}

Most students whose interest tend to the empirical will likely ``do"
statistics with the aid of apps, rather than by explicitly writing
programs that perform the required calculations.  That said, all
students should understand the crucial notion of {\em random variable}
and should be conversant with the most common statistical
distributions.  ``Conversant" in this context should include complete
understandings of the (low-numbered) moments of {\em at least} the
{\em uniform} and {\em exponential} distributions.  They should know
how to compute, say, the means and variances of various distributions
â€” and, most importantly, they should {\em understand} the sense in
which the variance of a distribution give {\em important} information
that is not available from the mean.  All of this is prerequisite to
rigor in experimentation.

\subsubsection{The Elements of Empirical Reasoning}

Empirical reasoning does not convey the certitude that formal
reasoning does.  Students should understand how to craft experiments
in a way that collects the ``right'' data.  The should then be
able---perhaps just with statistical packages---to interpret the
results they collect and to understand what conclusions are
justifiable.  {\em It is essential that all students understand the                  
  ditinction between {\em positive correlation} and {\em causation}!}
(Most of the public would seem to flunk that test.)

In order to satisfy the preceding demands, students should understand
enough about statistics---including definitions and meanings related
to distributions and their moments---to understand what conclusions
can be made based on experimental results, and to understand how to
describe conclusions in a way that is supported by the statistics.

\section{Beyond the Basics}

As students are introduced to modern topics within computing, whether
at the level of a Computing Literacy course or a post-core technical
course, they will have to master a variety of more specialized topics
that combine pieces of the elements we have discussed in this essay.
While these topics are beyond the level of generality aimed at in this
essay, some may be appropriate prerequisites to programs that have
some specialized foci.
\begin{itemize}
\item
Issues relating to {\em clustering} find application in applicatios as
diverse as: {\em linear-algebraic computations}, {\em data mining},
{\em design and layout of digital circuitry}.

\item
Issues building on {\em graph separation/decomposition} are
encountered when studying: {\em linear-algebraic computing}, {\em
  fault-tolerant design}, {\em load balancing}.

\item
Many issues relating to {\em fault/failure tolerance} and {\em data
  analytics} benefit from study using {\em random walks} (at least in
one dimension).

\item
Many useful ideas regarding the {\em encoding and manipulation of
  data} can be gleaned from the elements of {\em information theory}
and {\em computer arithmetic}.
\end{itemize}
The preceding list is really endless.  Hopefully readers will be
inspired by our few examples to compile a longer version that is
appropriate for their particular environments.





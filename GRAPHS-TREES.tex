%version of 12-30-18

\chapter{AN INTRODUCTION TO GRAPHS AND TREES}
\label{Ch:Graphs-Trees}
\index{graphs}

Graphs provide one of the richest technical and conceptual frameworks
in the world of computing.  They provide concrete representations of
manifold data structures, hence must be well understood in preparation
for a ``Data Structures and Algorithms'' course.  They embody tangible
abstractions of relationships of all sorts, hence must be well
understood in order to discuss entities as varied as web-search
engines and social networks with precision and rigor.  As with most of
the topics we discuss in this text, graph-oriented concepts must be
taught ``in layers''.  All students should be conversant with the use
of graphs to represent and reason about a vast array of complicated
relationships---ranging from taxonomies (including intra-family
structures) to link-based data structures to interconnectivity within
social media, and on and on---but the degree of sophistication that an
individual student requires depends both on the abilities of the
student and the range of graph-modeled concepts that will appear in
the student's program.  The most-basic concepts in this chapter should
be understood by all students in any academic program that includes a
computation-oriented component---although each concept can be
developed with more texture and nuance within the context of specific
application domains; the more advanced concepts should be selected
with care, based on the instructor's perception of students' needs, in
the light of the ever-growing importance of concepts involving
interconnectivity.

Many developments in computing technology over recent decades have
made it imperative that graphs no longer be viewed by students as the
static objects introduced early in the history of computational
studies.  For instance, while it was innovative in the 1960s to employ
graphs computationally as abstractions of data structures, such a view
is standard today.  Similar remarks, perhaps with differing dates, can
be made about graphs as vehicles for representing the flow of control
and information and as vehicles for representing interconnectivity
among both concepts and populations.  Applications ranging from
databases to web-search engines to social networks demand an
appreciation of graphs as dynamic objects.  This change in perspective
affects many aspects of the mathematical prerequisites for any
academic program that includes a computation-oriented component.

\section{Basic Concepts}
\label{sec:basic-graphs}

\subsection{Generic Graphs: Directed and Undirected}
\label{sec:graphs-generic}

\subsubsection{Connectivity-related concepts}

The basic components of a graph $\g$ are \index{graphs!nodes}
\index{graphs!vertices} \index{node (of a graph)} \index{vertex (of a
  graph)} its {\em nodes/vertices}\footnote{The singular form of
  ``vertices'' is {\it vertex}.}~(one encounters both terms in the
literature) and its {\em edges} \index{graphs!edges} \index{edge (of a
  graph)} that interconnect them.  (The singular form of ``vertices''
is {\it vertex}.)  \index{graphs!vertex} \index{vertex (of a graph)}
When graph $\g$ is {\em undirected}, \index{graphs!undirected} each of
its edges connotes some sort of sibling-like relationship among nodes
of ``equal'' status.  When graph $\g$ is {\em directed}
\index{graphs!directed} (sometimes referred to as a {\em digraph}),
\index{digraph} \index{graphs!digraphs} each of its edges connotes an
``unequal'' relationship such as parenthood or priority or dependence;
edges in directed graphs are often termed {\em
  arcs}. \index{graphs!arc} \index{arc (of a directed graph)}
\index{arc (of a digraph)} In many situations involving directed
graphs, it is important to recognize the {\em dual}
\index{graphs!digraph!dual} of a digraph $\g$.  This dual---which is
usually denoted by some notational embellishment of ``$\g$'', such as
$\widehat{\g}$---is the digraph obtained by {\em reversing} all of
$\g$'s arcs.  One sometimes encounters situations when arguments
about, or operations on, a digraph $\g$ can be ``translated'' to
arguments about, or operations on, $\widehat{\g}$ with only clerical
effort.  A {\em subgraph} $\g'$ of a graph $\g$ is a graph whose nodes
are a subset of $\g$'s and whose edges are a subset of $\g$'s that
interconnect only nodes of $\g'$.  A {\em path} \index{graphs!path}
\index{path (in a graph)} in an undirected graph is a sequence of
nodes within which every adjacent pair is connected by an edge.  A
path is a {\em cycle} \index{graphs!cycle} \index{cycle (in a graph)}
if all nodes in the sequence are distinct, except for the first and
last, which are identical.  Paths and cycles in directed graphs are
defined similarly, except that every adjacent pair of nodes must be
connected by an arc, and all arcs must ``point in the same
direction.''

The special class of graphs called {\it trees} \index{graphs!trees}
\index{trees} are identified mathematically as graphs that contain no
cycles or, equivalently, as graphs in which each pair of nodes is
connected by a unique path: a tree is thus the embodiment of ``pure''
connectivity.  As one would expect from the vernacular, a set of trees
is called a {\it forest}. \index{forest (of trees)} Just as with
graphs, there is a directed version of trees.  Within a directed tree
$\t$, one singles out two special classes of nodes: A {\it root
  (node)} \index{trees!root (node)} \index{root (of a directed tree)}
of $\t$ has no entering arcs; a {\it leaf (node)} \index{trees!leaf
  (node)} \index{leaf (of a directed tree)} of $\t$ has no exiting
arcs.  The reader is certainly familiar with the use of rooted
directed trees to represent family trees and corporate hierarchies.


A {\it directed graph} \index{graphs!directed} ({\it digraph},
\index{digraph} for short) $\g$ is given by a set of {\it nodes}
\index{graphs!node}
\index{$\n_{\fg}$: set of nodes of graph $\g$}
$\n_{\fg}$ and a set of {\it arcs}
\index{graphs!digraph!arcs}
(or {\it directed edges}) $\a_{\fg}$.
\index{$\a_{\fg}$: set of arcs of digraph $\g$}
Each arc of $\g$ has the form $(u \rightarrow v)$,
\index{$\rightarrow$: arc in a directed graph}
where $u, v \in \n_{\fg}$; we say that this arc goes {\em from} $u$
{\em to} $v$.  A {\it path} 
\index{graphs!path in a digraph}
\index{path in a digraph}
in the digraph $\g$ is a sequence of arcs that share adjacent
endpoints, as in the following $(n-1)$-arc path from node $u_1$ to
node $u_n$ in $\g$:
\begin{equation}
\label{eq:di-path}
(u_1 \rightarrow u_2), \ (u_2 \rightarrow u_3), \ \ldots, \ (u_{n-2}
        \rightarrow u_{n-1}), \ (u_{n-1} \rightarrow u_n)
\end{equation}
The path (\ref{eq:di-path}) is often written in the more succinct form
\[
u_1 \ \rightarrow \ u_2 \ \rightarrow \ u_3 \ \rightarrow \cdots
\rightarrow \ u_{n-2} \ \rightarrow \ u_{n-1} \ \rightarrow \ u_n
\]
The just-described path makes sense only when every node $u_i$ belongs
to $\n_{\fg}$ and every one of its arcs, $(u_i \rightarrow u_{i+1})$,
belongs to $\a_{\fg}$.  The {\it length} of path (\ref{eq:di-path}) is
the number of arcs, i.e., $n-1$.  The existence of the path means that
the {\it distance} \index{distance in a digraph}
\index{digraph!distance} \index{graphs!distance in a digraph} from
$u_1$ to $u_n$ in $\g$ is no greater than $n-1$.  (There may exist
shorter paths in $\g$ from $u_1$ to $u_n$.)

\medskip

It is sometimes useful to endow the arcs of a digraph with labels from
an alphabet $\Sigma$.  When so endowed, the path (\ref{eq:di-path})
would be written in a form such as

\smallskip

\hspace*{.35in}$\displaystyle
(u_1 \stackrel{\lambda_1}{\rightarrow} u_2), \ 
(u_2 \stackrel{\lambda_2}{\rightarrow} u_3), \ \ldots, \ 
(u_{n-2} \stackrel{\lambda_{n-2}}{\rightarrow} u_{n-1}), \ 
(u_{n-1} \stackrel{\lambda_{n-1}}{\rightarrow} u_n)$

\smallskip

\noindent
where the $\lambda_i$ denote symbols from $\Sigma$.  Labeled paths
also are often written in a succinct manner, as:

\smallskip

\hspace*{.35in}$\displaystyle 
u_1 \ \stackrel{\lambda_1}{\rightarrow} \ u_2
    \ \stackrel{\lambda_2}{\rightarrow} \ u_3
    \ \stackrel{\lambda_3}{\rightarrow} \ \cdots \ 
    \ \stackrel{\lambda_{n-3}}{\rightarrow} \ u_{n-2}
    \ \stackrel{\lambda_{n-2}}{\rightarrow} \ u_{n-1}
    \  \stackrel{\lambda_{n-1}}{\rightarrow} \ u_n$

\medskip

If $u_1 = u_n$, then we call path (\ref{eq:di-path}) a {\em (directed)
  cycle},\index{cycle (in a digraph)} and we call its labeled version
a {\em labeled (directed) cycle}.  (The qualifier ``directed'' is
usually included only for emphasis.)

\medskip

An {\em undirected graph} $\h$ is given by a set of nodes $\n_{\fh}$
and a set $\e_{\fh}$ 
\index{$\e_{\fh}$: the set of edges of the undirected  graph $\h$}
of $2$-element subsets of $\n_{\fh}$.  Each of these subsets is called
an {\it edge (of $\h$)}.
\index{graphs!edge} \index{edge (in a graph)}
One can, thus, view the undirected graph $\h$ as being obtained from a
directed graph $\bar{\h}$ by removing the directionality of
$\bar{\h}$'s arcs.  Whereas we say: \\
\hspace*{.35in}the {\em arc} $(u,v)$ goes {\em from} node $u$ {\em to}
node $v$ \\
we say: \\
\hspace*{.35in}the undirected edge $\{u,v\}$ goes {\em between} nodes
$u$ and $v$ \\
or, more simply: \\
\hspace*{.35in}the undirected edge $\{u,v\}$ {\em connects} nodes $u$
and $v$.  \\
One can view an undirected graph as asserting ``pure'' connectivity,
whereas directed graphs assert some form of priority or
directionality.

A {\it path} in an undirected graph \index{graphs!path in undirected
  graph} \index{path in and undirectd graph} is a sequence of
edges---i.e., of $2$-element sets of nodes---such that adjacent edges
share a node.  For illustration, an $(n-1)$-edge path that connects
nodes $u$ and $v$ in the undirected graph $\h$ has the form
\begin{equation}
\label{eq:undi-path}
\{u, u_1\}, \ \{u_1, u_2\}, \ \{u_2, u_3\}, \ \ldots, \ \{u_{n-2},
u_{n-1}\}, \ \{u_{n-1}, v\}
\end{equation}
The path described in (\ref{eq:undi-path}) makes sense only when every
node $u_i$ belongs to $\n_{\fh}$ and every edge $(u_i \ u_j\}$ belongs
to $\e_{\fh}$.  The {\it length} of path (\ref{eq:undi-path}) is the
number of edges---which is $n-1$ in this example; and the existence of
the path means that the {\it distance} \index{distance in a graph}
\index{graphs!distance} {\it between} $u$ and $v$ in $\h$ is no
greater than $n-1$.  (There may exist shorter paths that connect $u$
and $v$.)

\medskip

{\em Undirected} graphs are usually the default concept, in the
following sense: When $\g$ is described as a ``graph,'' with no
qualifier ``directed'' or ``undirected,'' it is usually understood
that $\g$ is an undirected graph.

\medskip

For each edge $\{u,v\} \in \e_{\fh}$, we call nodes $u$ and $v$ {\it
  neighbors} (in $\h$).
\index{neighbor node!in a graph}
The {\it degree}
\index{degree of a node in an undirected graph}
of a node $u \in \n_{\fh}$ is the number of neighbors that $u$ has.

Even at this early moment in our study of graphs, we can observe a few
important facts that can be useful when analyzing a broad range of
computation-related issues involving graphs (either as auxiliary
notions or as subjects of discourse).

\begin{prop}
\label{thm:number-edges/arcs}
{\bf (a)}
An $n$-node digraph $\g$ has no more than $n^2$ arcs.

{\bf (b)}
An $n$-node graph $\h$ has no more than $\displaystyle {n \choose 2}$ edges.

{\bf (c)}
An $n$-node (connected) tree has precisely $n-1$ edges.
\end{prop}

\begin{proof}
{\bf (a)}
The set $\a_{\fg}$ of arcs of $\g$ is a subset of the set of ordered
pairs of nodes of $\g$.  This latter number is clearly $n^2$, becaause
one can choose the first node in a pair in $n$ ways and then {\em
  independently} choose the second node in $n$ ways.

\smallskip

\noindent {\bf (b)}
The stated number is the number of $2$-node subsets of $\n_{\fh}$.  To
wit, start by listing the $n^2$ ordered pairs of nodes of $\h$.
First, eliminate from the list all $n$ pairs whose first and second
elements are equal: a set of the form $\{ u,u\}$ has only one element,
hence is not an edge of $\h$.  Then, for each distinct pair of nodes
$u, v \in \n_{\fh}$, eliminate one of the two ordered pairs, $\langle
u,v \rangle$ and $\langle u,v \rangle$: both of these ordered pairs
lead to the same unordered set $\{ u,v\}$, hence the same edge of
$\h$.  After these eliminations, we are left with
\[ \frac{n^2 - n}{2} \ = \ {n \choose 2} \]
$2$-element subsets of $\n_{\fh}$, from which we choose the edges of
$\h$.

\smallskip

\noindent {\bf (c)}
Let us proceed by induction on $n$.

The base case $n=2$ is obvious, because one edge is both necessary and
sufficient to connect two nodes.

Assume for induction that the indicated tally is correct for all trees
having no more than $k$ nodes.

Consider, for the purpose of extending the induction, any tree $\t$ on
$k+1$ nodes.  Easily, $\t$ must contain at least one leaf-node---i.e.,
a node $v$ of degree $1$---or else $\t$ would contain a cycle.  If we
remove $v$ and its incident edge, we now have a tree on $k$ nodes
which, by induction, has $k-1$ edges.  When we reattach node $v$, to
restore $\t$ to its original state, we see that $\t$ has $k+1$ nodes
and $k$ edges.

Because $\t$ was an arbitrary $(k+1)$-node tree, the induction is
extended.  \qed
\end{proof}


\begin{prop}
\label{thm:even-num-odd-degrees}
In any undirected graph, the number of nodes of odd degree is even.
\end{prop}

\begin{proof}
The result follows directly from the following equation that holds for
any undirected graph $\g$:
\[ \sum_{v \in {\cal N}_{\cal G}} \ \mbox{\sc degree}(v) \ = \ 2 \cdot
|\e_{\cal G}|.
\]
The equation holds because each edge $e$ of $\g$ ``touches'' two nodes
of $\g$, namely, $e$'s two endpoints.  Since the sum of $\g$'s
node-degrees is even, each odd node-degree must be paired (in the sum)
with another odd node-degree.  \qed
\end{proof}

\medskip

We sometimes use the term {\it neighbor} within the context of {\em
  directed} graphs also.  If we say that nodes $u$ and $v$ are
neighbors in the directed graph $\g$,
\index{neighbor node!in a directed graph}
then we mean that $\a_{\fg}$ contains at least one of the arcs $(u
  \rightarrow v)$ or $(v \rightarrow u)$.  More typically, we use
  terminology that is more faithful to digraph $\g$'s directedness.
If $\a_{\fg}$ contains the arc $(u \rightarrow v)$, then we would call
  $v$ a {\it (direct) successor} of $u$
\index{digraph!successor node}
\index{successor node in a directed graph}
and we would call $u$ a {\it (direct) predecessor} of $v$
\index{digraph!predecessor node}
\index{predecessor node in a directed graph}
The term {\it parent} often replaces ``predecessor node'', and the
term {\it child} often replaces ``successor node'', especially when
$\g$ is a directed {\em tree}.  Acknowledging the distinction between
predecessors and successors in digraphs, we usually split the notion
of the degree of a node within a digraph into the {\it indegree} and
the {\it outdegree} of node $u$:
\begin{itemize}
\item
The {\it indegree} of node $u \in \n_{\fg}$
\index{digraph!indegree}
is the number of nodes $v \in \n_{\fg}$ such that $(u \rightarrow v)$
is an arc of $\g$.
\item
Symmetrically, the {\it outdegree} of node $u \in \n_{\fg}$
\index{digraph!outdegree}
is the number of nodes $v \in \n_{\fg}$ such that $(v \rightarrow u)$
is an arc of $\g$.
\end{itemize}

\smallskip

The reader will note that we nowhere guarantee that there is always a
path that connects each node $u$ with each other node $v$.  We say
that a graph $\g$ is {\it connected} \index{graphs!connected} if every
pair of nodes $u, v \in \n_{\fg}$ is connected by a path in $\g$.  If
graph $\g$ is {\em not} connected, then it is the disjoint union of
some number $c$ of connected subgraphs, usually called $\g$'s {\it
  (connected) components}.  \index{graphs!connected components} Of
course, $g$ is connected just when $c=1$; i.e., there is a single
connected component.

\subsubsection{Distance-related concepts}

\noindent {\it Distance and diameter in a digraph.}
\index{digraph!distance between two nodes}
Extrapolating from our discussion of path (\ref{eq:di-path}): The {\it
  distance} from node $u_1$ to node $u_n$ in the digraph $\g$ is the
smallest number of arcs in any path from $u_1$ to $u_n$.  In detail:
\begin{equation}
\label{eq:di-distance-defn}
 \mbox{\sc distance}(u_1, u_n) \ \ \left\{
\begin{array}{cll}
= & 0 & \mbox{  if  } \ u_1 = u_n \\
\leq & n-1 & \mbox{  if there is a path } \ (\ref{eq:di-path})
\ \mbox{ from $u_1$ to $u_n$} \\
= & \infty & \mbox{  if there is no path } \ (\ref{eq:di-path})
\ \mbox{ from $u_1$ to $u_n$}
\end{array}
\right.
\end{equation}
The {\it diameter} \index{diameter in a digraph}
\index{digraph!diameter} of a directed graph $\g$ is the largest
distance between two nodes of $\g$, i.e., the largest number $d$ for
which there exist nodes $u_1, u_n \in \n_{\fg}$ such that {\sc
  distance}$(u_1, u_n) = d$.  Note that when discussing digraphs, we
always use {\em directed} paths when defining distance.

\medskip

\noindent {\it Distance and diameter in an undirected graph.}
\index{graphs!!distance between two nodes}
\index{diameter in a graph}
Extrapolating from our discussion of path (\ref{eq:undi-path}): The
{\it distance between} node $u_1$ and node $u_n$ in the graph $\g$ is
the smallest number of edges in any path from $u_1$ to $u_n$.  In
detail:
\begin{equation}
\label{eq:distance-defn}
 \mbox{\sc distance}(u, v) \ \ \left\{
\begin{array}{cll}
= & 0 & \mbox{  if  } \ u = v \\
\leq & n-1 & \mbox{  if there is a path } \ (\ref{eq:di-path})
\ \mbox{ between $u$ and $v$} \\
= & \infty & \mbox{  if there is no path } \ (\ref{eq:di-path})
\ \mbox{ between $u$ and $v$}
\end{array}
\right.
\end{equation}
The {\it diameter} \index{diameter in a graph} \index{graphs!diameter}
of an undirected graph $\h$ is the largest distance between two nodes
of $\h$, i.e., the largest number $d$ for which the exist nodes $u_1,
u_n \in \n_{\fh}$ such that {\sc distance}$(u_1, u_n) = d$.  Note that
when discussing undirected graphs, we always use {\em undirected}
paths when defining distance.

\ignore{********
Alternatively, this result can be proved by applying the Fubini's
principle using the adjacency matrix.  The two ways of counting the
non-zero elements are by rows (giving the sum of degrees) and globally.
\bigskip

Now, decompose this sum into even and odd degrees.

$\Sigma_{x \in V} \delta(x) = \Sigma_{x \in V_{even}} \delta(x) +
\Sigma_{x \in V_{odd}} \delta(x)$.

As $\Sigma_{x \in V_{even}} \delta(x)$ is obviously even as the sum of
even numbers, $\Sigma_{x \in V_{odd}} \delta(x)$ should also be even.

Thus, the number of odd vertices is even.% as depicted in Figure~\ref{propertyOdd}.
*************}

\bigskip

Our discussion of internode distances within graphs have focused on
shortest (or longest) path problems in {\em unweighted} graphs.  A
variety of important applications can be modeled via path-distance
problems in graphs $\g$ each of whose edges, say, $\{u,v\}$, is
weighted with a number that measures the cost of going between nodes
$u$ and $v$ in $\g$.  Of course, when graph $\g$ is directed, then the
arcs $(u \rightarrow v)$ and $(v \rightarrow u)$ can have different
weights, to model situations wherein going from $u$ to $v$ is
easier/cheaper than going from $v$ to $u$.  Happily, determining
shortest (or longest) paths in a directed or undirected graph $\g$ can
be accomplished ``efficiently''---which in the algorithmic world means
``in a number of steps that is polynomial in the size of $\g$''.
 

\subsubsection{Matchings in graphs}
\index{graphs!matching}

The notion of a {\it matching} in a graph is fundamental to many
situations that can be modeled using graphs.  A {\it matching} in an
undirected graph $\g$ is a set of edges of $\g$ that have no nodes in
common.  It is, thus, a formal mechanism for pairing nodes of a graph.
The broad array of activities that can be modeled using graph matching
include: pairing competitors for a tennis tournament; helping a person
select a potential spouse (which even in the vernacular is often
termed ``matchmaking''); determining (near-)optimal layouts for a
keyboard in language X (based on the relative ``affinities'' of
various pars of letters for one another in language X); selecting
persons to command the police stations in city Y (based on the
perceived ``match'' between a candidate's qualifications and the needs
of specific stations).  Even this small sampler of situations that
involve matchings makes it clear that there are many variations on
this formal theme.  This section is devoted to describing, and briefly
discussing, a few of the most commonly encountered versions of
matching in graphs.

\[ \approx \approx \approx \approx \approx \approx \approx \approx \approx \approx \]
Although the definitions of the various versions of matching are
readily accessible to even the beginning student of mathematics, munch
of the more sophisticated mathematical knowledge about matchings is
beyond any beginning text.  The interested reader might consult a more
advanced source, such as \cite{Berge73}, to get a feeling for what is
known about this simple, yet rich, topic.
\[ \approx \approx \approx \approx \approx \approx \approx \approx \approx \approx \]

\noindent {\it Matchings in unweighted graphs}.
The most straightforward notion of matching involves an undirected
graph $\g$ with unlabeled edges.  The optimization criterion most
often invoked with this genre of matching is to maximize the number of
edges of $\g$ that belong to the matching.

The target in this ``vanilla-flavored'' matching problem is often a
matching that is {\em maximal}, \index{graphs!maximal matching}
\index{graphs!maximal matching!unweighted graph} in the sense that
adding any further edge of $\g$ to the matching leaves one with a set
of edges that is no longer a matching.

Among maximal matchings in a graph $\g$, the ``ultimate treasure'' is
a matching that is {\it perfect}, \index{graphs!perfect matching} in
the sense that every node of $\g$ belongs to some edge of the
matching.

\begin{prop}
\label{thm:max-matching}
Maximal matchings exist for any graph $\g$.  One can find such a
matching in a number of steps proportional to $|\n_{\fg}|$.
\end{prop}

\begin{proof}
We leave to the reader the challenge of verifying that the following
\index{greedy algorithm} {\em greedy}\footnote{In the world of
  algorithmics, the term ``greedy'' descibes any process that seeks to
  satisfy a criterion as quickly as possible, with no consideration of
  how this choice affects future choices.}~process satisfies the
conditions of the Propositioon.

\noindent
{\it The Process:} \\
Begin by laying the nodes of $\g$ out, left to right, in any way.
Repeat the following process until no nodes remain in the layout.

\noindent
Select the leftmost node, $u$, in the remaining layout of $\n_{\fg}$.
Select the leftmost neighbor, $v$, of $u$ that remains in the layout.
  \begin{enumerate}
  \item
If you succeed in finding both $u$ and $v$, then add edge $\{u,v\}$ to
the matching we are building.  Remove both $u$ and $v$ from the
layout.
  \item
If there is no neighbor $v$ of $u$ in the remaining layout, then
remove node $u$ from the layout.
  \end{enumerate}
The real challenge here is to find a data structure that allows an
efficient search for a ``remaining'' neighbor-node $v$ at each step of
the selction process.
\qed
\end{proof}

\medskip

In contrast to maximal matchings, there exist myriad simple graphs
that do not admit any perfect matching.  Contemplating, for instance,
matchings within any cycle with an odd number of nodes may prepare the
reader for the challenge of verifying the following necessary
condition for a graph to admit a perfect matching.

\begin{prop}
\label{thm:necessary-for-perfect-matching}
Let $\g$ be a graph that admits a perfect matching.  Then:
\begin{itemize}
\item
$\g$ has an even number of nodes.
\item
The cardinality of the (perfect) matching---i.e., the number of edges
in the matching---is exactly
$\frac{1}{2}|\n_{\fg}|$.
\end{itemize}
\end{prop}


\bigskip

\noindent {\it Matchings in weighted graphs}.
The other very popular genre of matching problem focuses on graphs
each of whose edges, say, $\{u,v\}$, is weighted with a number that
measure the ``affinity'' of  nodes $u$ and $v$ for each other.  The
challenge is to find a matching that is {\em maximal}
\index{graphs!maximal matching} in the sense of having a cumulative
sum of edge-weights that is not exceeded by any other matching's.

We note in closing that, while edge-weightings often complicate
computational processing of graphs, they need not render such
computations practically infeasible.  For instance, the problem of
discovering a perfect matching of minimal weight in an edge-weighted
graph can be solved moderately efficiently---i.e., in a number of
steps that is polynomial in the size of the graph.  (An algorithm that
achieves this efficiency can be based on the colorfully named {\it
  Hungarian assignment method}; \index{Kuhn, Harold W.}  see the
original source \cite{Kuhn55} or the encyclopedic algorithms text
\cite{CLRS}.)

\subsection{Trees}
\label{sec:Trees}

The special class of graphs called {\it trees} \index{graphs!trees}
\index{trees} occupy a place of honor within both the mathematical
field called {\it graph theory} and within the vernacular.

Mathematically speaking, a tree is a graph that contains no cycles,
i.e., is {\it cycle-free}. \index{graphs!cycle-free} Equivalently, a
tree is a graph in which each pair of distinct nodes is connected by
precisely one path.  A tree is thus the embodiment of ``pure''
connectivity: it provides the minimal interconnection structure that
provides paths that connect every pair of nodes.  As one might expect
from the vernacular, a set of trees is called a {\it
  forest}. \index{forest (of trees)}

We have just given two distinct definitions of ``tree''.  The reader
should prove that both definitions define the same class of graphs.

\begin{prop}
\label{thm:2defns-trees}
Prove that the two definitions of ``tree'' are equivalent.  In other
words, prove that the following assertions about a connected graph
$\t$ are equivalent, in the sense that one assertion holds if, and
only if, the other does.
\begin{itemize}
\item
The graph $\t$ is cycle-free.
\item
Each pair of distinct nodes of $\t$ is connected by precisely one
path.
\end{itemize}
\end{prop}

{\Arny A GOOD EXERCISE?}

One of the major uses of trees and forests is as a way of succinctly
``summarizing'' the connectivity structure inherent in an undirected
graph.  This role is inherent in the notion of a {\it spanning tree}
\index{graphs!spanning tree} \index{spanning tree} of a connected
graph $\g$.  A spanning tree of $\g$ is a tree $\t(\g)$ whose node-set
is identical to $\g$'s:
\[ \n_{\ft(\fg)} \ = \ \n_{\fg} \]
and all of whose edges are edges of $\g$:
\[ \e_{\ft(\fg)} \ \subseteq \ \e_{\fg}. \]
Not surprisingly, a connected graph $\g$  typically has {\em many}
spanning trees.  All such trees share $\g$'s node-set, but they may
choose quite different sets of edges.

{\Arny Chance for some exercises here}

For a graph $\g$ that is not connected, we replace the notion of
spanning tree of $\g$ with the analogous notion of a {\it spanning
  forest} \index{graphs!spanning forest} \index{spanning forest} of
$\g$.  We shall typically discuss only spanning trees in this section,
leaving the reader to extrapolate the discussion to include spanning
forests of unconnected graphs.

The major use of spanning trees in applications is to ``summarize''
the full connectivity structure of a graph---and of the entities that
the graph models, such as a map, the layout of a museum, etc.  When
used in this way, the edges of spanning trees are typically {\em
  weighted}, \index{graphs!spanning tree!edge-weighted} in order to
model a ``cost'' of incorporating that edge in the tree.  The types of
computational problem modeled via edge-weighted spanning trees
include: the optimal placement of firehouses, or hospitals, in a town
and the optimal deployment of security mechanisms in an art museum.
Reflecting problems wherein edge-weights measure transit costs, it is
a classical computational problem to seek a {\em minimum-weight
  spanning tree} \index{graphs!minimum-weight spanning tree}
\index{minimum-weight spanning tree} (or, in the vernacular, a {\em
  minimum spanning tree}).  Happily, this classical optimization
problem can be solved within a number of steps that is linear in the
number of edges of $\g$ \cite{CLRS}.

{\Arny Giving just a {\em hint} at a solution for MST to real
  beginners is probably useless}
\ignore{*********
There are mainly two ways for constructing such a MST, each one
emphasizes a different propriety of the MST, namely, avoid cycles and
minimize the span.  In both cases, the edges are sorted in increasing
order of weights.  More precisely, the first one constructs a subtree
which partially spans the graph by adding at each step the minimum
neighboring edge while the other add successively the edges of minimal
weights that do not create a cycle.
*************}

Just as with graphs, there is a {\em directed} version of trees, which
is formed by replacing the (unoriented) edges of an undirected tree by
(oriented) arcs.  Within a directed tree, one often says that an arc
goes from a {\it parent node} \index{trees!parent node} to a {\it
  child node} \index{trees!child node}.  Extending this
anthropomorphic metaphor, one often talks about the {\it ancestor(s)}
\index{trees!ancestor node} and {\it descendant(s)}
\index{trees!descendant node} of a tree-node.  We single out two
special classes of nodes of a directed tree: A {\it root (node)}
\index{trees!root (node)} \index{root (of a directed tree)} is defined
by its having no entering arcs; a {\it leaf (node)} \index{trees!leaf
  (node)} \index{leaf (of a directed tree)} is defined by its having
no exiting arcs, i.e., outdegree $0$.

\[ \approx \approx \approx \approx \approx \approx \approx \approx \approx \approx \]
Sociologically, the historical {\it atomic family tree} \index{family
  tree} has two roots, representing the matriarch and patriarch of the
family.  The entirety of the tree represents a single family
generationally, before any children form their own families.  All
child-nodes in this genre of tree are the roots of singly-rooted
subtrees of the entire family tree.  The leaves of the tree are the
childless descendants of the roots.  Note that, while we are using
anthropomorphic language here, we could be discussing other genres of
``family'', as, e.g., many types of biological taxonomies.
\[ \approx \approx \approx \approx \approx \approx \approx \approx \approx \approx \]

Among rooted directed trees, an important subclass comprises those
that have a {\em single root} which has a directed path to every other
node.  The length of each such directed path is often used to label
the {\it generation}
\index{generation of a node in a singly-rooted directed tree}
of the node at the end of the path: root, child, grandchild,
great-grandchild, etc.
Every node of the tree is the root of a singly-rooted directed
subtree of the entire tree.  All subtrees that are rooted at nodes of
the same generation are mutually disjoint.

\[ \approx \approx \approx \approx \approx \approx \approx \approx \approx \approx \]
A singly-rooted tree represents a {\it hierarchy}.
\index{trees!singly-rooted!hierarchy} \index{hierarchy} Given two
directed subtrees within a hierarchy, either the root of one of the
subtrees is a descendant of the root of the other, or the two subtrees
are are mutually disjoint.
\[ \approx \approx \approx \approx \approx \approx \approx \approx \approx \approx \]

More formally: {\em rooted trees} are a class of {\em acyclic}
digraphs.  Paths in trees which start at the root are often called
{\em branches}.  The {\em acyclicity} of a tree $\t$ means that for
any branch of $\t$ of the form (\ref{eq:di-path}), we cannot have $u_1
= u_n$, for this would create a cycle.  Each singly-rooted tree $\t$
has a designated {\em root node} \index{trees!root node} $u_n \in
\n_{\ft}$ that resides at the end of a branch (\ref{eq:di-path}) that
starts at $r_{\ft}$ (so $u_1 = r_{\ft}$) is said to reside at {\em
  depth} $n-1$ in $\t$; by convention, $r_{\ft}$ is said to reside at
depth $0$.  \index{depth of a node in a singly-rooted trees} $\t$'s
root $r_{\ft}$ has some number (possibly $0$) of arcs that go from
$r_{\ft}$ to its {\em children,} each of which thus resides at depth
$1$ in $\t$; in turn, each child has some number of arcs (possibly
$0$) to its children, and so on.  For each arc $(u \rightarrow v) \in
A_{\ft}$, we call $u$ a {\it parent} \index{trees!parent node} of $v$,
and $v$ a {\it child} \index{trees!child node} of $u$, in $\t$;
clearly, the depth of each child is one greater than the depth of its
parent.  Every node of $\t$ except for $r_{\ft}$ has precisely one
parent; $r_{\ft}$ has no parents.  A childless node of a tree is a
{\em leaf}, \index{trees!leaf node} i.e., a node of degree $1$.  The
transitive extensions of the parent and child relations are,
respectively, the {\em ancestor} \index{trees!ancestor node} and {\em
  descendant} \index{trees!descendant node} relations.  The {\em
  degree} \index{degree (of a node in a tree)} of a node $v$ in a tree
is the number of children that the node has, call it $c_v$.  If every
nonleaf node in a tree has the same degree $c$, then we call $c$ the
{\em degree of the tree}.  \index{degree of a tree}

It is sometimes useful to have a symbolic notation for the ancestor
and descendant relations.  To this end, we write $(u \Rightarrow v)$
\index{$\Rightarrow$: ancestor/descendant in a rooted tree} to
indicate that node $u$ is an {\it ancestor} of node $v$, or
equivalently, that node $v$ is a {\it descendant} of node $u$.  If we
decide that we are not interested in {\em really distant} descendants
of the root of a tree $\t$, then we can {\em truncate} \index{truncated}
$\t$ at a desired depth $d$ by removing all nodes whose depths exceed
$d$.  We thereby obtain the {\em depth-$d$ prefix} of $\t$.

\ignore{****************
Figure \ref{fig.graph-samples} depicts an arc-labeled rooted tree $\t$
whose arc labels come from the alphabet $\{a,b\}$.  $\t$'s arc-induced
relationships are listed in Table~\ref{tab.graph-samples}.
\begin{figure}[htb]
\centerline{\epsfig{figure=graph.sample.eps,height=4truecm}}
\caption{An arc-labeled rooted tree $\t$ whose arc labels come from
  the alphabet $\{a,b\}$.  (Arc labels have no meaning; they are just
  for illustration.)
\label{fig.graph-samples}}
\end{figure}
\begin{table}[htb]
{\small
\begin{center}
\fbox{
\begin{tabular}{c||c|c|c|c}
\multicolumn{5}{c}{The arc-labeled rooted tree $\t$ of
  Figure \ref{fig.graph-samples}} \\
\hline
Node            & Children & Parent & Descendants & Ancestors \\
\hline
\hline
$r_{\ft} = u_0$ 
& $u_1$
& none & 
$u_1, u_2, \ldots, u_k, v_1, v_2, \ldots, v_k,
w_1, w_2, \ldots, w_k$
& none \\
\hline
$u_1$
& $u_2, v_1$
& $u_0$ & 
$u_2, \ldots, u_k, v_1, v_2, \ldots, v_k, w_1, w_2, \ldots, w_k$
& $u_0$ \\
\hline
$u_2$
& $u_3, v_2$
& $u_1$ & 
$u_3, \ldots, u_k, v_2, \ldots, v_k, w_2, \ldots, w_k$
& $u_0$ \\
\hline
 $\vdots$ & $\vdots$ & $\vdots$ &  $\vdots$ &  $\vdots$ \\
\hline
$u_k$
& $v_k$ 
& $u_{k-1}$ & 
$v_k, w_k$
& $u_0, u_1, \ldots, u_{k-1}$ \\
\hline
$v_1$
& $w_1$ 
& $u_1$ & 
$w_1$
& $u_0, u_1$ \\
\hline
$v_2$
& $w_2$
& $u_2$ & 
$w_2$
& $u_0, u_1, u_2$ \\
\hline
 $\vdots$ & $\vdots$ & $\vdots$ &  $\vdots$ &  $\vdots$ \\
\hline
$v_k$
& $w_k$
& $u_k$ & 
$w_k$
& $u_0, u_1, \ldots, u_k$ \\
\hline
$w_1$
& none
& $v_1$ & 
none
& $u_0, u_1, v_1$ \\
\hline
$w_2$
& none &
$v_2$ & 
none
& $u_0, u_1, u_2, v_2$ \\
\hline
$w_k$
& none
& $v_k$ & 
none
& $u_0, u_1, \ldots, u_k, v_k$
\end{tabular}
}
\end{center}
}
\caption{A tabular description of the rooted tree $\t$ of
  Figure \ref{fig.graph-samples}.  \label{tab.graph-samples}}
\end{table}
*********************}

\subsection{Significant ``Named'' Families of Graphs}
\label{sec:graphs-important-families}

The mathematical discipline called graph theory is an important source
of formal aids for the activities of designing, analyzing, utilizing,
and verifying computer systems.  Of course, computer systems are
designed by humans.  Among other consequences of this fact is the
observations that the graphs that are among the most commonly used to
structure systems tend to be rather uniform in structure, in a variety
of possible ways.  Such graphs, when drawn, often exhibit a lot of
structural symmetry.  One popular form of symmetry is {\it degree
  regularity}: an undirected graph $\g$ is {\it regular}
\index{graphs!regular} if all nodes of $\g$ have the same degree.  Not
surprisingly, there is a directed version of ``regular'' embodied in the
symmetric notions of {\it in-regularity}
\index{graphs!directed!in-regular} and {\it out-regularity}.
\index{graphs!directed!out-regular}

\medskip

We now describe five families of regular graphs that have proven
useful over the history of digital computing, and we expose some basic
properties of each, including its diameter.  Each of these graphs is
available in both a directed and an undirected version, although, as
we note, one of these versions is more commonly encountered.  We have
selected these specific graphs for rather different reasons.
\begin{itemize}
\item
The first two graphs, the {\it cycle-graph} of paragraph {\small\sf A}
and the {\it complete graph} of paragraph {\small\sf B} were selected
for respectively representing the lowest-degree and highest-degree
graphs that share two properties: (1) every node of each graph is
accessible from every other node; (2) all nodes ``look alike'' to
someone traversing the graph.  Elaborating on (2): If we put you down
on a node of either graph, there is no way that you can determine the
identity of that node.  This is an important feature to ponder,
because it is a simple instance of the anonymity problem inherent to
many modern distributed computing environments.  {\it How does one
  orchestrate cooperative activities when all agents ``are
  identical''?}

\item
The remaining graphs, the {\it mesh and torus networks}\footnote{These
  two structures, though distinct, are usually discussed together
  because they share so many important properties.}~of paragraph
{\small\sf C}, the {\it hypercube network} of paragraph {\small\sf D},
and the {\it de Bruijn network} of paragraph {\small\sf E}, were
selected for their importance within the world of parallel and
distributed computing---as abstract platforms for developing efficient
computational and communicational processes, and as abstract versions
of the networks that underlie parallel architectures by
interconnecting its processors.
\end{itemize}
Throughout, the parameters that describe our graph families range over
the positive integers; i.e., each occurrence of $n$ below ranges over
$\N^+$.

\subsubsection{The cycle-graph}

For each positive integer $n \in \N^+$, both the {\it undirected
  order-$n$ cycle-graph} $\cc_n$ and the {\it directed order-$n$
  cycle-graph} $\widehat{\cc}_n$ \index{cycle graph} \index{cycle
  network} have {\it node-set}
\[ \n_{{\cal C}_n} \ = \ \n_{\widehat{{\cal C}}_n}
\ = \ \{ 0, \ 1, \ \ldots, \ n-1\}. \]
\begin{itemize}
\item
$\cc_n$ has $n$ edges; its {\it edge-set} is
\[ \e_{{\cal C}_n} \ = \
\big\{ \{i, \ i+1 \bmod n\} \ \ | \ \ i \in \{0, \ 1, \ \ldots,
\ n-1\} \big\}.
\]
  \begin{itemize}
  \item \index{cycle graph!node-degree}
$\cc_n$ is a regular network: each node has degree $2$.

Specifically, each node $i$ of $\cc_n$ has its {\it predecessor} $i-1
\bmod n$ \index{cycle graph!predecessor node} \index{cycle
  graph!successor node} and its {\it successor} $i+1 \bmod n$ .
  \item \index{cycle graph!diameter}
$\cc_n$ has diameter $\lfloor n/2 \rfloor$.

Direct calculation shows that $\cc_n$'s diameter is no larger than
this.  The fact that this is, in fact, the graphs's diameter is
witnessed by the distance betewen each node $k \in \n_{{\cal C}_n}$
and its antipodal node $k + \lfloor n/2 \rfloor \bmod n$.
  \end{itemize}

\item
$\widehat{\cc}_n$ has {\it arc-set}
\[ \a_{\widehat{{\cal C}}_n} \ = \ 
\big\{ (i \rightarrow i+1 \bmod n) \ \ | \ \ i \in \{0, \ 1, \ \ldots, \ n-1\} \big\}
\]
  \begin{itemize}
  \item \index{cycle graph!directed node-degree}
$\widehat{\cc}_n$ is a regular network: each node has the same
    indegree and the same outdegree.  Coincidentally, both the common
    indegree and the common outdegree are $2$.
  \item
$\widehat{\cc}_n$ has (directed) diameter $n-1$.

Of course, $n-1$ is an upper bound on the diameter of any $n$-node
digraph.  The fact that this is exactly the graph's diameter is
witnessed by the directed distance from each node $k$ of $\widehat
{\cc}_n$ to its predecessor node $k-1 \bmod n$.
  \end{itemize}
\end{itemize}

\subsubsection{The complete graph, or, clique}
\index{complete graph}

For each positive integer $n \in \N^+$, we denote by $\k_n$ the {\em
  undirected} order-$n$ {\it complete-graph} (or, {\it clique}),
\index{complete graph} \index{clique} and by $\widehat{\k}_n$ the {\em
  directed} order-$n$ {\it complete-graph} (or, {\it clique}).  Both
$\k_n$ and $\widehat{\k}_n$ have {\it node-set}
\[ \n_{{\cal K}_n} \ = \ \n_{\widehat{{\cal K}}_n}
\ = \ \{ 0, \ 1, \ \ldots, \ n-1\}. \]
\begin{itemize}
\item
$\k_n$ has $\displaystyle {n \choose 2}$ edges; its {\it edge-set} is
\[ \e_{{\cal K}_n} \ = \
\big\{ \{i, \ j\} \ \ | \ \ i,j \in \{0, \ 1, \ \ldots, \ n-1\}, \ i
\neq j \big\}.
\]
  \begin{itemize}
  \item \index{complete graph!node-degrees} \index{clique!node-degrees}
$\k_n$ is a regular network: each node has degree $n-1$; every node $i
\in \n_{\fk_n}$ is connected with all other nodes.

   \item \index{complete graph!diameter}
$\k_n$ has diameter $1$.

$\k_n$'s diameter is a direct consequence of its node-degrees, and vice versa.
  \end{itemize}

\item
$\widehat{\k}_n$ has $(n-1)n$ arcs; its {\it arc-set} is
\[ \a_{\widehat{{\cal K}}_n} \ = \ 
\big\{ (i \rightarrow j) \ \ | \ \ i,j \in \{0, \ 1, \ \ldots, \ n-1\}
\big\}, \ i \neq j
\]
  \begin{itemize}
  \item
$\widehat{\k}_n$ is a regular network: each node has the same indegree
    and the same outdegree.  Both the common indegree and the common
    outdegree are $n-1$.
  \item
$\widehat{\k}_n$ has (directed) diameter $1$.

As in the undirected case, there is a causal relationship between
$\widehat{\k}_n$'s diameter and its (in- and out-) node-degrees.
  \end{itemize}
\end{itemize}

Hearkening back to our discussion of matchings in (unweighted) graphs:
The structure of the set of perfect matchings in general graphs is
decidely nontrivial.  For clique-graphs, though, the structure is much
easier to discuss.

\begin{prop}
\label{thm:perfect-matchings-clique}
The number of perfect matchings admitted by the clique-graph $\k_n$ is
either $0$---if $n$ is odd---or exponential in $n$ if $n$ is even.
\end{prop}

\begin{proof}
The assertion about cliques with odd numbers of nodes is immediate
from Proposition~\ref{thm:necessary-for-perfect-matching}.

We verify the assertion about cliques of the form $\k_{2k}$ by
induction on $k$.  To this end, let $M_n$ denote the number of perfect
matchings that the clique $\k_n$ admits.

The base of our induction is the case $k=1$.  Because $\k_{2}$
consists of a single edge, it admits only one perfect matching; i.e.,
$M_1 = 1$.
%(see Figure~\ref{perfectMatching1}): 

To garner intuition, we also explcitly solve the case $k=2$, which is
illustrated in Fig.~\ref{fig:AllPerfectMatchings}.
\begin{figure}[hbt]
\begin{center}
       \includegraphics[scale=0.55]{FiguresGraph/perfectmatchingAll}
       \caption{The three different perfect matchings in the $4$-node
         clique $\k_4$: the matchings' edges are drawn, respectively,
         with bold lines, dashed lines, and dotted lines.}
%of one matching are drawn in bold;
% The optimal one is represented in bold (the two others are in dashed and dot lines).}
  \label{fig:AllPerfectMatchings}
\end{center}
\end{figure}
As the figure illustrates, $\k_4 = \k_{2 \cdot 2}$ can be viewed as a
$4$-cycle (drawn with bold and dashed lines), augmented by two
``cross-edges'' (drawn with dotted lines).  Easily, then, $\k_4$
admits $3$ different perfect matchings, which can be identified (and
specified) by the edge that contains the northwesterly node---call it
$v$---in the figure.  Node $v$ has the choice of three nodes to
``boldly'' match with. (In the figure, $v$ has chosen the
southwesterly node as its ``bold'' match.)  Once $v$ has chosen its
match, there is only one viable choice for the second edge in the
matching.  Thus, $M_2=3$.

We jump now to the case of any arbitrary $k > 2$.  We remark that
there are precisely $2k-1$ nodes of $\k_{2k}$ that node $1$ can
``choose'' as its mate in a perfect matching.  Once we set node $1$
and its chosen mate aside, we confront an independent instance of the
problem with parameter $k-1$, i.e., the problem of counting the number
of perfect matchings in $\k_{n-2} = \k_{2k-2}$.  We thereby note that
as $k$ grows, the quantity $M_k$ obeys the following recurrence:
\[ M_k \ = \ (2k-1) \cdot M_{k-1} \]
In other words:

\hspace*{.25in}{\em $M_k$ is the product of the first $k$ odd numbers.}
%$N_1=1$, $N_2=3$, $N_3=3 \times 5=15$, $N_4=3 \times 5 \times 7=115$, etc..

\noindent
To gauge the growth rate of $M_k$, we concentrate on cases $k > 2$ and
ignore the $\lfloor k/2 \rfloor$ smallest odd numbers.  We then
replace each of the remaining odd numbers by its smallest possible
value.  We thereby find that
\[
M_k \ \ =    \ \ \prod_{i=1}^k \ (2i-1)
    \ \ \geq \ \ \prod_{\lceil k/2 \rceil}^k \ (2i-1)
    \ \ \geq \ \ \left( 2 \lceil k/2 \rceil -1 \right)^{k/2}
    \ \ >    \ \ k^{k/2}
\]
In summary, $M_k$ grows exponentially with the parameter $k$, as claimed.
\qed
\end{proof}


\bigskip

The two families of graphs we have just discussed, cycles and cliques,
are recommended to our attention by their structural simplicity---they
epitomize, respectively, the most sparse way (the cycle) and the most
dense way (the clique) to completely interconnect $n$ nodes.  The
remainder of this section is devoted to three graph-structures that
are structurally more complex than cycles and cliques, which have been
designed to meet specific needs within the real technological world of
computing and communicating.  Indeed, the three upcoming graph
families are among the most important ones when discussing parallel
and distributed computing (PDC, for short).  All three families have
been used both to design computer architectures that support PDC and
to craft algorithms that exploit the potential efficiencies---in
computation and communication---that one can achieve using PDC.

\subsubsection{The mesh and torus networks}
\label{sec:mesh-torus}
\index{mesh and torus networks}

For positive integers $m, n \in \N^+$, both the $m \times n$ {\it mesh
  (network)} $\m_{m,n}$ and the $m \times n$ {\it toroidal network}
(or, {\it torus}) $\widetilde{\m}_{m,n}$ have {\it node-set}
\begin{eqnarray*}
\n_{\fm_{m,n}} \ = \ \n_{\widetilde{\fm}_{m,n}}
  & = & 
\{1, \ 2, \ldots, \ m\} \ \times \ \{1, \ 2, \ldots, \ n\} \\
  & = & 
\big\{ \langle i, \ j \rangle \ \ | \ \ 
\big[ i \in \{1, \ 2, \ldots, \ m\} \big], \ \
\big[ j \in \{1, \ 2, \ldots, \ n\} \big]
\big\}
\end{eqnarray*}

\begin{itemize}
\item
$\m_{m,n}$ has $(m-1)n \ + \ (n-1)m$ edges; its {\it edge-set} is
\begin{eqnarray*}
\e_{\fm_{m,n}} & = & 
\big\{
\{ \{ i, j \}, \ \{ i+1, j \} \ \ | \ \
1 \leq i < m, \ \ 1 \leq j \leq n \} \\
  &  & \hspace*{.1in} \cup
\{ \{ i, j \}, \ \{ i, j+1 \} \ \ | \ \
1 \leq i \leq m, \ \ 1 \leq j < n \}
\big\}
\end{eqnarray*}

  \begin{itemize}
  \item
    \begin{itemize}
    \item
The subgraph of $\m_{m,n}$ defined by the node-set
\[ \{ \langle i, \ j \rangle  \ \ | \ \ \left[i \in \{1, 2, \ldots,
  m\}\right], \ \ \left[1 \leq j < n\right]\}
\]
and all edges both of whose endpoints belong to that set is called the
$i$th {\it row} of $\m_{m,n}$
\index{row of a mesh graph}
\index{mesh graph!row}
Dually, the subgraph of $\m_{m,n}$ defined by the node-set
\[ \{ \langle i, \ j \rangle  \ \ | \ \ \left[j \in \{1, 2, \ldots,
  n\}\right], \ \ \left[1 \leq i < m\right] \}
\]
and all edges both of whose endpoints belong to that set is called the
$j$th {\it column} of $\m_{m,n}$.
\index{column of a mesh graph}
\index{mesh graph!column}
     \item
Nodes $\langle 1, \ 1 \rangle$, $\langle 1, \ n \rangle$, $\langle m,
\ 1 \rangle$, and $\langle m, \ n \rangle$ are the {\it corner nodes}
(or, just {\it corners}) of $\m_{m,n}$.
\index{corner (node) of a mesh graph}
\index{mesh graph!corner (node)}
     \item
The path-graph consisting of the node-set
\[ \{ \langle 1, \ 1 \rangle, \ \langle 1, \ 2 \rangle, \ldots, \
\langle 1, \ n \rangle \}
\]
together with all edges of $\m_{m,n}$ both of whose endpoints belong
to this set, is the {\it top edge} of $\m_{m,n}$.
\index{top edge of a mesh graph}
\index{mesh graph!top edge}

The other edges of $\m_n$ are defined analogously:

\smallskip

The {\it bottom edge} of $\m_{m,n}$ is the path-graph built upon the
node-set
\[ \{ \langle m, \ 1 \rangle, \ \langle m, \ 2 \rangle, \ldots, \
\langle m, \ n \rangle \}
\]
\index{bottom edge of a mesh graph}
\index{mesh graph!bottom edge}

The {\it left edge} of $\m_{m,n}$ is the path-graph built upon the
node-set
\[ \{ \langle 1, \ 1 \rangle, \ \langle 2, \ 1 \rangle, \ldots, \
\langle m, \ 1 \rangle \}
\]
\index{left edge of a mesh graph}
\index{mesh graph!left edge}

The {\it right edge} of $\m_{m,n}$ is the path-graph built upon the
node-set
\[ \{ \langle 1, \ n \rangle, \ \langle 2, \ n \rangle, \ldots, \
\langle m, \ n \rangle \}
\]
\index{left edge of a mesh graph}
\index{mesh graph!right edge}
     \end{itemize}

  \item \index{mesh graph!node-degree}
$\m_{m,n}$ is {\em not} a regular graph.  Its corner nodes each has
    degree $2$; its non-corner edge nodes each has degree $3$; its
\index{internal node of a mesh graph}
\index{mesh graph!internal node}
{\em internal nodes}---which are all non-edge nodes---each has degree
$4$

  \item \index{mesh graph!undirected diameter}
The diameter of $\m_{m,n}$ is $m+n-2$, as witnessed by the distance
between nodes $\langle 1, \ 1 \rangle$ and $\langle 2, \ n \rangle$.
  \end{itemize}

\item
$\widetilde{\m}_{m,n}$ has $2mn$ arcs; its {\it arc-set} is
\begin{eqnarray*}
\a_{\widetilde{\m}_{m,n}} & = &
\big\{
\{ (\langle i, \ j \rangle \rightarrow \langle i+1 \bmod m, \ j
\rangle) \ \ | \ \ 1 \leq i \leq m, \ \ 1 \leq j \leq n \} \\
  &  & \hspace*{.1in} \cup
\{ (\langle i, \ j \rangle \rightarrow \langle i, \ j+1 \bmod n
\rangle) \ \ | \ \ 1 \leq i \leq m, \ \ 1 \leq j \leq n \}
\big \}
\end{eqnarray*}

  \begin{itemize}
  \item
The subgraph of $\widetilde{\m}_{m,n}$ defined by the node-set
\[ \{ \langle i, \ j \rangle  \ \ | \ \ \left[i \in \{1, 2, \ldots,
  m\}\right], \ \ \left[1 \leq j \leq n\right]\}
\]
and all edges both of whose endpoints belong to that set is called the
$i$th {\it row} of $\widetilde{\m}_{m,n}$
\index{torus graph!row}
Dually, the subgraph of$\widetilde{\m}_{m,n}$ defined by the node-set
\[ \{ \langle i, \ j \rangle  \ \ | \ \ \left[j \in \{1, 2, \ldots,
  n\}\right], \ \ \left[1 \leq i \leq m\right] \}
\]
and all edges both of whose endpoints belong to that set is called the
$j$th {\it column} of $\widetilde{\m}_{m,n}$.
\index{torus graph!column}
  \item
$\widetilde{\m}_{m,n}$ is a regular network; each node has degree $4$.
    Despite the fact that $\widetilde{\m}_{m,n}$ is an {\em
      undirected} graph, its arcs are commonly referred to via an
    anthropomorphic labeling, either as ``up, down, left, and right''
    or as ``north, south, west, and east''.
  \item \index{mesh graph!directed diameter}
$\widetilde{\m}_{m,n}$'s diameter is $\lfloor m/2 \rfloor \ + \
\lfloor n/2 \rfloor$.  This can be verified in analogy to the diameter
of the cycle-graph $\cc_n$.
  \end{itemize}
\end{itemize}

\subsubsection{The boolean hypercube network}
\index{boolean hypercube}
\index{hypercube}

The graphs we focus on in this section have had a major impact on the
world of coding, especially in regard to codes that are {\em error
  correcting} \cite{PetersonW81}, and the world of computing,
especially in regard to parallel and distributed computing
\cite{JohnssonH1989, SaadS89, Schwartz80}.  The cited sources give a
range of perspectives on the importance of {\it hypercube networks.}

\index{order-$n$ boolean hypercube}
The {\it order-$n$ boolean hypercube}, traditionally denoted $\q_n$,
is the $2^n$-node graph defined as follows.
\begin{itemize}
\item
{\it The recursive definition}. 
\index{order-$n$ boolean hypercube!recursive definition}
  \begin{itemize}
  \item
The order-$0$ boolean hypercube, $\q_0$, has a single node, and no
edges.
  \item
The order-$(k+1)$ boolean hypercube, $\q_{k+1}$, is obtained by taking
two copies of $\q_k$, call them $\q_k^{(1)}$ and $\q_k^{(2)}$, and
creating an edge that connects each node of $\q_k^{(1)}$ with the
corresponding node of $\q_k^{(2)}$.
  \end{itemize}
For illustration:
  \begin{itemize}
  \item
$\q_1$ consists of two nodes connected by a single edge.
  \item
$\q_2$ can be viewed as a ``square'', or equivalently, a copy of $\cc_4$.
  \item
$\q_3$ can be viewed as a ``cube'', i.e., as two copies of $\cc_4$
    with edges connecting corresponding nodes: Each of the following
    pairs of nodes are connected by an edge: the upper right
    corner-nodes, the upper left corner-nodes, the lower right
    corner-nodes, and the lower left corner-nodes.
  \end{itemize}

\item
{\it The direct definition}.
For each $n \in \N$, the nodes of the order-$n$ boolean hypercube,
$\q_n$, are all length-$n$ binary strings.  For illustration:
\index{order-$n$ boolean hypercube!direct definition}
\begin{eqnarray*}
\n_{{\fq}_0}
  & = & 
\{ \varepsilon \}, \ \ \mbox{ the length-$0$ {\em null string}} \\ 
\n_{{\fq}_1}
  & = &
\{ 0, \ 1 \} \\
\n_{{\fq}_2}
  & = & \{ 00, \ 01, \ 10, \ 11 \} \\
\n_{{\fq}_3}
  & = & \{ 000, \ 001, \ 010, \ 011, \ 100, \ 101, \ 110, \ 111 \} 
\end{eqnarray*}
Easily, for each value of $n$, $\q_n$ has $2^n$ nodes, for this is the
number of length-$n$ binary strings.

\medskip

For each value of $n$, each edge of $\q_n$ connects two node-strings
that differ in precisely one position.  This means that $\q_n$ has $n
2^{n-1}$ edges: To wit, each of its $2^n$ nodes has $n$ neighbors, so
the quantity $n 2^n$ counts each of $\q_n$'s edges twice---one for
each endpoint.  For illustration:
\begin{eqnarray*}
\a_{{\fq}_1}
  & = &
\big\{ \{ 0, \ 1 \} \big\} \\
\a_{{\fq}_2}
  & = & \big\{
\{ 00, \ 01 \}, \ \{ 00, \ 10\}, \
\{ 01, \ 11 \}, \ \{ 10, \ 11\} 
\big\} \\
\a_{{\fq}_3}
  & = & \big\{ 
\{000, \ 001\}, \
\{000, \ 010\}, \
\{000, \ 100\}, \
\{001, \ 011\}, \\
  &  & \hspace*{.2in}
\{001, \ 101\}, \
\{010, \ 011\}, \
\{010, \ 110\}, \
\{100, \ 101\}, \\
  &  & \hspace*{.2in}
\{100, \ 110\}, \
\{101, \ 111\}, \
\{011, \ 111\}, \
\{110, \ 111\}
\big\}
\end{eqnarray*}
\end{itemize}

\medskip

\noindent
It is easy to observe $\q_n$'s basic structural properties.
\begin{itemize}
\item \index{hypercube!node-degree}
$\q_n$ is a regular network: each of its $2^n$ nodes has degree $n$.

This follows from the fact that each arc of $\q_n$ rewrites a single
bit-position in the length-$n$ binary string that is the arc's source
node.

\item \index{hypercube!diameter}
$\q_n$ has diameter $n \ = \ \ln(|\n_{\fq_n}|)$.\footnote{Recall that
  $\ln n = \log_2 n$; see Section~\ref{sec:logarithmic-fns}.}

We address this issue formally.
\end{itemize}

\begin{prop}
\label{thm:hypercube-diameter}
For all $n \in \N^+$, $\q_n$ has diameter $n \ = \ \ln(|\n_{\fq_n}|)$.
\end{prop}

\begin{proof}
We prove this diameter bound by construction.  Focus on two arbitrary
nodes of $\q_n$:
\[ x \ = \ \alpha_1 \alpha_2 \cdots \alpha_n \ \ \ \mbox{ and } \ \ \
y \ = \ \beta_1 \beta_2 \cdots \beta_n
\]
One of the several paths in $\q_n$ from $x$ to $y$ is described
schematically as the following left-to-right, bit-by-bit rewriting of
$x$ as $y$ using arcs of $\q_n$
\[
x \ = \ \alpha_1 \alpha_2 \cdots \alpha_n \ \rightarrow \
\beta_1 \alpha_2 \cdots \alpha_n \ \rightarrow \
\beta_1 \beta_2\cdots \alpha_n \ \rightarrow \cdots \rightarrow\ 
\beta_1 \beta_2 \cdots \beta_n \ = \ y
\]
Since each bit of each string is rewritten once, the bound follows.
\qed
\end{proof}

\medskip

The fact that $\q_n$'s diameter is {\em logarithmic} in its size makes
$\q_n$ an efficient network for many tasks related to parallel
computing and communication.

\subsubsection{The de Bruijn network}
\index{de Bruijn network}
\index{de Bruijn graph}

While the family of hypercube networks has few competitors in the
world of parallel and distributed computing, in terms of performance
and ease of designing algorithms, it does have one major shortcoming
regarding its realization in hardware.  The basic problem is that the
order-$n$ hypercube has large node-degrees, specifically logarithmic
in the size of the network.  This feature makes the hypercubes actual
performance much lower than its theoretical performance.
Specifically, the size of the hypercube grows exponentially with the
common degrees of the network's nodes---this is the ``inverse'' way
of talking about logarithmic node-degrees---while the space in which
we (and our computers) live grows only cubically with linear
distance.  The resulting disparity means that the wires in a large
hypercube must inevitably be very long---in contrast to the unit-size
of idealized network-edges.  Consequently, electrical signals within a
large hyeprcube must travel long distances, which means that the
physical computer is much slower than its idealized version.  (One
finds a more technical discussion of this phenomenon in
\cite{Ullman84}.)

The preceding shortcoming of hypercubes led researchers to seek a
family of networks whose node-degrees stay constant even as one
deploys successively larger instances of the network.  A candidate
such network was discovered within the domain of coding theorists (as,
coincidentally, was the hypercube).  

In the mid-20-century, Dutch mathematican Nicolaas Govert de Bruijn
\index{de Bruijn, Nicolaas Govert} discovered a way to generate
compact sequences that contain all possible strings of a prespecified
length.  Focussing on {\em binary} strings---although de Bruijn's
strategy works for any finite alphabet---de Bruijn could generate a
string of length $2^n +n-1$ that contains every length-$n$ binary
string as a substring.  Quite appropriately, such a string is called a
{\it de Bruijn sequence}. \index{de Bruijn sequence} It is not obvious
that de Bruijn sequences exist for every $n$, but we now plant the
seeds of a proof that they do.  We begin by illustrating two sample
sequences in (\ref{eqn:deBruijn-seq}).
\begin{equation}
\label{eqn:deBruijn-seq}
\begin{array}{|l||c|c|}
\hline
n & \mbox{\sc Length-$n$ binary strings}
    & \mbox{\sc Order-$n$ de Bruijn sequence} \\
\hline
\hline
1 &
00, \ 01, \ 10, \ 11  & 00110 \\
\hline
2 &
\begin{array}{l}
000, \ 001, \ 010, \ 011, \\
100, \ 101, \ 110, \ 111 
\end{array}
  & 0001110100 \\
\hline
\end{array}
\end{equation}
The table in (\ref{eqn:deBruijn-seq}) spawns many interesting
questions:
\begin{itemize}
\item
Do de Bruijn sequences exist for every $n$?
\item
If so, 
  \begin{itemize}
  \item
How does one compute them?
  \item
Can one always find a de Bruijn sequence of length $2^n +n-1$?
  \item
Can one find de Bruijn sequences of length $< 2^n +n-1$?
  \end{itemize}
 {\Arny (SOME GOOD EXERCISES HERE)}  
\end{itemize}
The answers to all of these questions---and the connection of de
Bruijn sequences to the current chapter---reside in the family of
directed graphs called {\it de Bruijn graphs} (or, {\it networks}).
\index{de Bruijn graph} \index{de Bruijn network} (The term used
varies by intended application---mainly, coding theory and [the
  interconnection networks of] parallel computer architectures.  We
use the names interchangeably.)

For every integer $n \in \N^+$, the {\it order-$n$ de Bruijn network}
is the {\em directed} graph $\d_n$ whose nodes comprise the set of
length-$n$ binary strings\footnote{While {\em binary} de Bruijn
  networks are the most frequently encountered ones, one can also find
  de Bruijn networks whose nodes comprise all length-$n$ strings over
  larger finite alphabets.  Such extended families also find
  applications in coding theory.}  The sets $\n_{\fd_2}$ and
$\n_{\fd_3}$ appear in (\ref{eqn:deBruijn-seq}).

$\d_n$ is a regular directed graph; its nodes all have in-degree $2$
and outdegree-$2$.  Each node of $\d_n$ is a binary string of
length $n \geq 1$; hence it can be written in the form $\beta x$,
where $\beta \in \{0, \ 1\}$ is a {\it bit} (short for {\it binary
  digit}) and $x$ is a length-$(n-1)$ binary string.

The $2^{n+1}$ arcs of $\d_n$ come in pairs specified as follows.  For
each $\beta \in \{0,1\}$ and for each length-$(n-1)$ binary string
$x$, $\d_n$ has the two arcs
\[ (\beta x \rightarrow x0) \ \ \ \mbox{ and } \ \ \ 
(\beta x \rightarrow x1)
\]
We enumerate $\a_{\fd_3}$ in (\ref{eqn:deBruijn-arcs}).
\begin{equation}
\label{eqn:deBruijn-arcs}
{\small
\begin{array}{|ccccc|}
\hline
\mbox{\sc Source node} & & \mbox{\sc Target node} & & \mbox{\sc Target node} \\
\hline \hline
{\displaystyle
\left.
\begin{array}{c}
000 \\
001 \\
010 \\
011 \\
100 \\
101 \\
110 \\
111
\end{array}
\right\}
} &
\mbox{\sc goes to} 
  &
{\displaystyle
\left\{
\begin{array}{c}
000 \\
010 \\
100 \\
110 \\
001 \\
011 \\
101 \\
111
\end{array}
\right.
}
  &
\mbox{\sc and to}
  &
{\displaystyle
\left\{
\begin{array}{c}
001 \\
011 \\
101 \\
111 \\
000 \\
010 \\
100 \\
110
\end{array} 
\right.
}
 \\
\hline
\end{array}
}
\end{equation}

For each $n \in \N^+$, $\d_n$ has diameter $n$.  To see why this is
true, note that following any one of $\d_n$'s arcs, say from node $x$
to node $y$, consists of ``rewriting'' the length-$n$ string $x$ as
the length-$n$ string $y$.  The diameter bound therefore follows by
showing that, for any two string-nodes of $\d_n$, say node $u$ and
node $v$, one can rewrite string $u$ as string $v$ by traversing a
sequence of arcs---i.e., a directed path---of length at most $n$.
Observe, for instance, that the path in $\d_3$ described schematically
as follows
\[ 000 \ \rightarrow \ 001 \ \rightarrow \ 011 \ \rightarrow \ 111 \]
leads node $000$ to node $111$, by rewriting string $000$ as string
$111$.  The diameter bound is now an immediate consequence of the
following result.

\begin{prop}
\label{thm:deBruijn-hamiltonian}
For all $n \in \N^+$, $\d_n$ contains a {\em directed hamiltonian
  cycle}, 
\index{directed hamiltonian cycle in a digraph}
i.e., a length-$2^n$ directed cycle of the form
\begin{equation}
\label{eq:deBruijn-cycle}
 x \ \rightarrow \ y_1 \ \rightarrow \ y_2 \ \rightarrow \cdots
\ \rightarrow \ y_{2^n-1} \ \rightarrow \ x
\end{equation}
that contains every node of $\d_n$ precisely once; i.e.:
\begin{itemize}
\item
$\{x, \ y_1, \ y_2, \ldots, \ y_{2^n-1}\} \ = \ \n_{\fd_n}$.
\item
All of the ``$y$-nodes'' that appear in cycle
(\ref{eq:deBruijn-cycle}) differ from $x$ and from each other.
\end{itemize}
\end{prop}

The simplest proof of this result has two steps, each of which
introduces a topic we have not yet developed.

\medskip

\noindent {\bf (1)}
%
For any directed graph $\g$, the {\it line digraph} \index{line graph}
\index{line digraph} of $\g$, denoted $\Lambda(\g)$, is the following
directed graph.
\begin{itemize}
\item
The nodes of $\Lambda(\g)$ are the arcs of $\g$:
\[ \n_{{\cal L}({\cal G})} \ = \ \a_{\fg} \]
\item
For each pair of arcs of $\g$ of the form
\[ \big[a_{x,y} = (x \ \rightarrow \ y) \big] \ \ \ \mbox{ and } \ \ \ 
\big[a_{y,z} = (y \ \rightarrow \ z) \big]
\]
i.e, arcs such that the endpoint of the first arc is the source of the
second arc, $\Lambda(\g)$ contains an arc $(a_{x,y} \ \rightarrow
\ a_{y,z})$.
\end{itemize}
The relevance of this topic to this section is that the line graph of
every de Bruijn network $\d_n$ is the ``next bigger'' de Bruijn
network, $\d_{n+1}$.  Let us verify this claim.

\begin{prop}
\label{thm:deBruin-linegraph}
For all $n \in \N^+$,
$\d_{n+1}$ is the line digraph of $\d_n$: $\d_{n+1} \ = \ \Lambda(\d_n)$.
\end{prop}

\begin{proof}
Each node of $\Lambda(\d_n)$ is an arc of $\d_n$, hence has the form
\[ (\beta x \ \rightarrow \ x \gamma) \]
for $x$ a length-$(n-1)$ binary string and $\beta, \gamma \in
\{0,1\}$.  Let us associate node $\beta x \gamma$ of $\d_{n+1}$ with
this node of $\Lambda(\d_n)$.

\smallskip

Note first that each arc of $\d_{n+1}$ has the form
\[ (\delta y \varepsilon \ \rightarrow \ y \varepsilon \varphi), \]
where $y$ is a length-$(n-2)$ binary string and $\delta, \varepsilon,
\varphi \in \{0,1\}$.  By our association of nodes of $\d_{n+1}$ with
arcs of $\d_n$, this arc of $\d_{n+1}$ does, indeed, correspond to two
successive arcs of $\d_n$.   The first of these successive arcs
{\em enters} node $y \varepsilon$ of $\d_n$; the second {\em leaves}
that node.

Note next that, given any two successive arcs of $\d_n$, say
\[
(\rho \sigma z \ \rightarrow \ \sigma z \tau) \ \ \ \mbox { and } \ \ \
(\sigma z \tau \ \rightarrow \  z \tau \xi)
\]
where $z$ is a length-$(n-2)$ binary string and $\rho, \sigma, \tau,
\xi \in \{0,1\}$, there is, indeed, an arc of $\d_{n+1}$ of the form
\[ (\rho \sigma z \tau \ \rightarrow \ \sigma z \tau \xi) \]
This means that the digraph $\d_{n+1}$ is identical to the digraph
$\Lambda(\d_n)$, modulo a renaming of nodes and arcs.\footnote{Technically,
  we are asserting that the digraphs ${\cal D}_{n+1}$ and ${\cal
    L}({\cal D}_n)$ are {\it isomorphic} to one another.  The topic of
  graph isomorphism is beyond the scope of this text, but our informal
  description provides all the details one would need to formalize the
  described isomorphism.}

The described correspondence between the nodes and arcs of $\d_{n+1}$
and $\Lambda(\d_n)$ completes the proof.  \qed
\end{proof}

\medskip

\noindent {\bf (2)}
{\it Eulerian cycles}. \index{Eulerian cycle}
A {\it directed eulerian cycle}\footnote{This notion is named for its
  discoverer, Leonhard Euler \index{Euler, Leonhard}.}~in a digraph
$\g$ is a directed cycle that contains each arc of $\g$ precisely
once.  We will see, later in this chapter, a truly elementary argument, based
on node-degrees, which proves that every de Bruijn digraph has a directed
eulerian cycle.  This demonstration will combine with
Proposition~\ref{thm:deBruin-linegraph} to complete the proof of
Proposition~\ref{thm:deBruijn-hamiltonian}.  \qed
%\end{proof}

\bigskip

Stepping back from the structural specifics of $\d_n$, we now see that
de Bruijn networks provide us with a {\em
  bounded-degree---specifically, a degree-$2$} family of networks each
of whose constituent graphs has {\em logarithmic diameter}!  In this
regard, at least, de Bruijn networks have exactly the same
cost-performance as hypercubes---i.e., $2^n$-node graphs with diameter
$n$---with bounded degrees.  Even more dramatic, it has been shown
that sophisticated algorithmic techniques can achieve roughly
equivalent computational efficiency, on a broad range of significant
computational problems, using de Bruijn networks as using like-sized
hypercubes \cite{AnnexsteinBR90, BermondP89, Ullman84}.


\section{Path and Cycle Problems in Graphs}
\label{sec:path-cycle-problems}

Just as various genres of {\it spanning trees} are used to
``summarize'' aspects of the connectivity structure of a connected
graph $\g$, various genres of {\it paths} and {\it cycles} in $\g$ are
often useful to ``summarize'' aspects of $\g$'s traversal structure.

**HERE






\subsection{Path problems}

The main interest of graphs is to determine \textit{paths}, i.e. how vertices are connected to each other (determine if they are connected, find the shortest or the longest paths, count the number of edge disjoint paths, etc.). 

There are two types of problems: those which concern the edges and those which concern the vertices. 
In this sense, these problems are \textit{dual}.
However, surprisingly, determining a \textit{tour} (i.e. a cycle) that visits exactly once each edge is an easy problem
 while determining a tour that visits exactly once each vertex is hard. 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Eulerian cycles}
\label{sec:eulerianCycle}

\subsection{Existence}

Let us first consider the problem of determining a cycle which visits all the edges of a given (undirected) graph $G=(V,E)$ exactly once.
This problem of determining if such a tour (called \textit{eulerian cycle}) exists is one of the oldest problem in the field of Operational Research
(it was introduced in 1736). 
It has been studied by the famous swiss mathematician Leonard Euler for the specific case of a tour going through all the bridges of the Koenigsberg town. 
The graph is called \textit{eulerian} if it admits such an eulerian cycle.
The solution of this problem is characterized by the following proposition.
\bigskip

\noindent {\bf Proposition.}
A connected graph is eulerian {\it iff} all its vertices have an even degree.
\bigskip

We distinguish below two types of proofs based on the same claims, one is simply the existence while the other one provides a solution. 
Let us first establish three basic claims (elementary facts) that will be useful.
\bigskip

\noindent {\bf Claim 1.}
if all the degrees are even (and not null) then there exists a cycle.\bigskip

\noindent {\bf Claim 2.}
A tour is an union of disjoint cycles.\bigskip

\noindent {\bf Claim 3.}
If we remove a cycle in a tour then the degrees remain even.\bigskip

The necessary condition of the proposition is straightforward. 
Let us focus on the sufficient condition.
\bigskip

\noindent {\bf Proof 1 (existence).}

By contradiction, let us assume that all the vertices of a connected graph are even and there is no tour that contains all the edges.
Let consider a tour with a maximum number of edges. 
If we remove its edges, it remains some edges and from Claim~3 they are even.
Then, from Claim~1, there exists a cycle within these remaining edges (say $\Gamma$). 
The contradiction comes from Claim~2 since the union of the maximal tour plus the cycle $\Gamma$ 
is another tour which contains more edges than the initial one.
\bigskip

\noindent This proof can be adapted in a constructive way and thus, leads to an algorithm. It is as follows:

\noindent {\bf Proof 2 (constructive).}
By induction on the number of edges. 

\begin{itemize}
\item The basis case is simple to verify for $m=2$ (where two vertices linked by two edges correspond to the cycle of minimal length). 
\item
Let consider a connected graph with $m+1$ edges where all its vertices have an even degree.
Let assume that the property holds for connected graphs of even vertices with $k$ edges ($k \leq m$), which means there exist eulerian tours in these sub-graphs. 

From Claim~1, there exists a cycle (let denote it by $\Gamma$ described by its successive vertices) and consider the sub-graph of $G$ 
without the edges of $\Gamma$: $G'=(V-{\Gamma},E')$. 
By induction hypothesis, there exists an eulerian cycle $\mathcal{C}_i$ in each connected component of $G'$ 
(from Claim 3).
The eulerian tour of $G$ is obtained by the concatenation of pieces of $\Gamma$ and the eulerian cycles in the successive $\mathcal{C}_i$.

\end{itemize}


{\bf APPLICATION}

\begin{corol}
\label{thm:deBruijn-Eulerian}
Every de Bruin network $\d_n$ is (directed)-Eulerian.
\end{corol}

\subsection{Chinese postman problem}
\label{sec:chinesePostman}

Let us now present the more general problem of determining a cycle that contains all the edges in any graph, in particular when
there exist some odd vertices. From the previous section, we know that there is no eulerian cycle in this case and thus, 
any feasible solution should duplicate some edges.
The problem is to duplicate the minimum.
This problem is known as the {\it chinese postman} and it is described below (in a french equivalent version).

A postman moved recently from Grenoble to a small village in the country side. 
He asked himself how to organize his daily tour by bike for distributing the letters in the shortest possible time. 
The director of the post office gives him the map and 
fortunately, the postman had some old souvenir of previous lectures in Graph Theory.  
The tour starts from the post office and of course, the postman has to go through every roads for distributing the letters before coming back
to his office.
The underlying graph is $G=(V,E)$ where $V$ is the (finite) set of cross points and $E$ is the set of the links between the cross roads
weighted by the distances.  

Fig.~\ref{fig:eulerianInitial} presents an example of the chinese postman problem. 
\begin{figure}[hbt]
\begin{center}
       \includegraphics[scale=0.6]{FiguresGraph/EulerienInitial}
       \caption{Example of an instance of the chinese postman with $10$ cross vertices.}
              \label{fig:eulerianInitial}
\end{center}
\end{figure}

\bigskip

This problem may be formulated mathematically in term of eulerian cycles.
Intuitively, the basic idea is to duplicate some edges that are carefully chosen in order to use the previous construction
of an eulerian tour of section~\ref{sec:eulerianCycle} that will help the postman to determine 
the optimal tour (of minimal length) using some simple mathematical properties. 
\bigskip

First, we know that there is an even number of odd vertices.
Considering the previous instance of the postman problem, there are $4$ such vertices (represented in grey in Fig.~\ref{fig:eulerianVodd}).

\begin{figure}[hbt]
\begin{center}
       \includegraphics[scale=0.6]{FiguresGraph/EulerienVodd}
       \caption{The $4$ vertices with an odd degree in the previous instance.}
              \label{fig:eulerianVodd}
\end{center}
\end{figure}
\bigskip

As there exists a path between any pair of vertices of odd degree in $V_{odd}$,
we consider the complete graph whose vertices are the odd degree vertices weighting the edges with the shortest paths (denoted by $K_{odd}$).
As we mentioned in the preliminary properties, computing the shortest paths is a classical problem, which can be solved in polynomial time. 

\begin{figure}[hbt]
\begin{center}
       \includegraphics[scale=0.6]{FiguresGraph/EulerienPerfectMatching}
       \caption{The minimum weight perfect matching labelled by the shortest distances between the vertices of $V_{odd}$.}
              \label{fig:eulerianperfectmatching}
\end{center}
\end{figure}
\bigskip

Then, it is possible to do the correspondence between the optimal solution of the postman problem and a perfect matching of minimal weight in $K_{odd}$
%Recall that a matching is a set of edges without common vertices. It is perfect if it has the maximum number of edges. 
by duplicating the edges of the minimal perfect matching.

\begin{figure}[hbt]
\begin{center}
       \includegraphics[scale=0.6]{FiguresGraph/EulerienFinal}
       \caption{Final step: adding the edges of the minimum perfect matching.}
              \label{fig:eulerianFinal}
\end{center}
\end{figure}

The main steps of the algorithm for determining the optimal tour are the following:

\begin{itemize}
\item Consider the complete graph with the odd vertices and compute its weight by the shortest paths.
Compute a perfect matching of minimal weight between these vertices. 
\item Duplicate all the edges along the paths of this matching.
\item Determine an eulerian tour in this new graph with even degrees.
\end{itemize}

The optimality of this algorithm comes from the fact that the duplicated edges are the minimum possible ones.
% This is straightforward for two odd vertices.
Finally, all the vertices of the new graph are even since the degree of the odd vertices in $G$ is augmented by $1$
(extremities of the paths) and the other even vertices which are intermediate vertices of the paths remain even. 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Hamiltonian Paths and Cycles/Tours}
\label{sec:hamiltonian-cycle}

\subsubsection{Hamiltonianicity in unweighted graphs}
\label{sec:hamiltonian-unweighted}

We turn now to the problem of determining when a connected graph $\g$
has a cycle that contains every node of $\g$ precisely once---and the
allied problem of finding such a cycle when one exists.  Such a cycle
is called a {\it Hamiltonian cycle},\footnote{Note that words and
  phrases deriving from Hamilton's name, such as ``Hamiltonian cycle''
  and ``Hamiltonianicity'', tend to retain their capitalization, but
  one does sometimes encounter ``hamiltonian cycle'' and
  ``hamiltonianicity''.  Hamilton is, thus, not totally immune from
  the incursions of familiarity that have led to ``abelian group'' and
  ``naperian logarithm''.}~or \index{graphs!Hamiltonian cycle}
\index{Hamiltonian cycle} {\it Hamiltonian circuit},
\index{graphs!Hamiltonian circuit} \index{Hamiltonian circuit} in
honor of the British mathematician William Rowan Hamilton,
\index{Hamilton, William Rowan} who is credited with inventing the
concept in the mid-19th century.  When one views a Hamiltonian cycle
as a ``map'' for traversing a graph, one often calls the cycle a {\it
  Hamiltonian tour}.  Traditionally, one says that a graph that admits
a Hamiltonian cycle is {\it Hamiltonian}, or is a {\it Hamiltonian
  graph}. \index{graphs!Hamiltonian} \index{Hamiltonian graph}

One can envision a number of benefits rendered accessible by a
Hamiltonian cycle in a graph $\g$.  Most obviously, the cycle
specifies a tour of $\g$ (or of a map whose structure $\g$ abstracts)
  which visits each of $\g$'s nodes precisely once.

\paragraph{\small\sf A. Seeking more inclusive notions of Hamiltonianicity}

Many graphs---even ones with ``nice'' structures---do not admit
Hamiltonian cycles.  The reader can generate {\it mesh-graphs}
(Section~\ref{sec:mesh-torus}) that admit no Hamiltonian cycle.  The
existence of such non-Hamiltonian graphs has spawned several
independent paths of inquiry.  One path seeks ``modest'' ways to
weaken the property of {\it Hamiltonianicity}
\index{graphs!Hamiltonianicity} in a way that retains many of
Hamiltonianicity's benefits while encompassing a braoder range of
graph structures.  We describe two avenues toward weakened, more
inclusive, notions of Hamiltonianicity.

\noindent {\it Be satisfied with paths, rather than cycles}.
A {\it Hamiltonian path} \index{graphs!Hamiltonian path}
\index{Hamiltonian path} in a graph $\g$ is a path that passes through
each of $\g$'s nodes precisely once.  Hamiltonian paths can easily be
shown to be a strictly weaker notion than Hamiltonian cycles, in the
following sense.  Obviously, every graph that admits a Hamiltonian
cycle also admits a Hamiltonian path: one just drops any single edge
of such a cycle to obtain such a path.  However, there are many graphs
that admit a Hamiltonian path that do not admit any Hamiltonian cycle.
As suggested earlier, there exist mesh-graphs that admit no
Hamiltonian cycle, even though every mesh-graph admits a Hamiltonian
path.  This latter claim is verified by a path that traverses the rows
of a mesh-graph {\it seriatim}, in alternating directions.

\noindent {\it Be satisfied with short paths, rather than edges}.
A Hamiltonian cycle in graph $\g$ is a circular enumeration of $\g$'s
nodes in which adjacent nodes are at unit distance from one
another---i.e., are connected by an edge.  We can weaken (or,
generalize) this notion to create a {\it Hamiltonian $k$-cycle}
\index{graphs!Hamiltonian $k$-cycle} in $\g$, for any positive integer
$k$: This is a circular enumeration of $\g$'s nodes in which adjacent
nodes are at distance $\leq k$ from one another---so a Hamiltonian
$1$-cycle is what we have been calling a Hamiltonian cycle.  In fact,
the following result shows that one need not let $k$ be very big
before one encompasses all connected graphs.  Regrettably, the proof
of this result is beyond the current text.

\begin{prop}
\label{thm:weak-hamiltonianicity}
{\bf (a)} {\rm \cite{ChartrandK69}}
Let $\g$ be any connected graph.  One can cyclically enumerate the
nodes of $\g$ in such a way that nodes that are adjacent in the cycle
are at distance $\leq 3$ in $\g$.


\noindent {\bf (b)} {\rm  \cite{Fleischner74}}
Let $\h$ be any graph that is {\em $2$-connected}
\index{graphs!$2$-connected} \index{graphs!biconnected} (or, {\it
  biconnected}) in the sense that, for every two nodes, $u$ and $v$,
of $\h$, there exist at least two node-disjoint paths in $\h$ that
connect $u$ and $v$.  One can cyclically enumerate the nodes of $\h$
in such a way that nodes that are adjacent in the cycle are at
distance $\leq 2$ in $\h$.
\end{prop}

\paragraph{\small\sf B. Understand Hamiltonianicity in important graphs}

Yet another direction of inquiry is to determine whether specific
graphs of interest are Hamiltonian.  We illustrate this avenue by
reviewing the five important families of graphs we studied in
Section~\ref{sec:graphs-important-families}.

\begin{prop}
\label{thm:named-graph-hamiltonian}
{\bf (a)}
Every cycle-graph $\cc_n$ is Hamiltonian.

\noindent {\bf (b)}
Every clique-graph $\k_n$ is Hamiltonian.

\noindent {\bf (c)}.1.
For all $m,n$: the mesh-graph $\m_{m,n}$:

(i)  is path-Hamiltonian.

(ii) contains no odd-length cycle; hence, is not Hamiltonian if $mn$
is odd.

(iii) is Hamiltonian whenever $mn$ is even 

\noindent {\bf (c)}.2.
For all $m,n$: the torus-graph $\widetilde{\m}_{m,n}$ is Hamiltonian.

\noindent {\bf (d)}
Every hypercube $\q_n$  is Hamiltonian.

\noindent {\bf (e)}
Every de Bruijn network $\d_n$ is (directed)-Hamiltonian.
\end{prop}

\begin{proof}
\noindent {\bf (a)}
This is a tautology, by definition of $\cc_n$.

\medskip

\noindent {\bf (b)}
This is immediate because, by definition, $\k_n$ contains every
$n$-node graph---including $\cc_n$---as a subgraph.

\medskip

\noindent {\bf (c)}.1.i.
As we noted earlier in the text, one can ``snake'' a path through
$\m_{m,n}$, row by row, from the top-most to the bottom-most.  By
``snake'', we mean that one should traverse adjacent rows in
alternating directions.

\noindent {\bf (c)}.1.ii.
This is a consequence of the fact that $\m_{m,n}$ is {\it bipartite}:
\index{graphs!bipartite} One can color $\m_{m,n}$'s nodes ed and blue
in such a way that every edge connect nodes of different colors.
Details are left to the reader.

\noindent {\bf (c)}.1.iii.
We sketch the construction of a Hamiltonian cycle in $\m_{m,n}$ when
$mn$ is even.  Say, with no loss of generality that $m$ is even, so
that $\m_{m,n}$ has an even number of rows.  Temporarily remove column
$1$ of $\m_{m,n}$, and consruct the ``snaking'' Hamiltonian path
described in part {\bf (c)}.1.i of this proof.  Because $m$ is even,
this path begins and ends in column $2$ of $\m_{m,n}$.  One can,
therefore, replace column $1$ and use it to connect the ends of the
``snaking'' Hamiltonian path.  This describes a Hamiltonian cycle in
$\m_{m,n}$.

\noindent {\bf (c)}.2.
When $mn$ is even, the Hamiltonianicity of $\widetilde{\m}_{m,n}$
follows from the fact that $\m_{m,n}$ is a spanning subgraph of
$\widetilde{\m}_{m,n}$.  (Think about it!)  When $mn$ is odd, one
needs just traverse $\widetilde{\m}_{m,n}$'s nodes row by row, going
to the cyclically next node after completing each row.  Details are
left to the reader.

\medskip

\noindent {\bf (d)}
One can craft a Hamiltonian cycle in $\q_n$ by
generating an {\it order-$n$ binary reflected Gray code}---so named
for its inventor, Bell Laboratories researcher \index{Gray, Frank}
Frank Gray; see \cite{PetersonW81}.  \index{Gray code} \index{binary
  reflected Gray code} Such a ``code'' is a cyclic enumeration of all
$2^n$ binary strings of length $n$ having the property that cyclically
adjacent \index{strings!cyclically adjacent} strings differ in only
one bit-position.  Length-$n$ strings $x_i$ and $x_j$ are {\it
  cyclically adjacent} in the Gray code $\langle x_0, \ x_1, \ldots,
x_{2^n-1} \rangle$ if $j = i+1 \bmod 2^n$.

\noindent
It is computationally easy to generate an order-$n$ Gray code from an
order-$(n-1)$ Gray code, as follows.

We note first that the order-$1$ code is the sequence $\langle 0, 1
\rangle$.

Inductively, to generate the order-$(k+1)$ Gray code from the
order-$k$ code:
\begin{itemize}
\item
Concatenate the order-$k$ code with a {\em reversed} copy of itself.
(It is the code-sequence that is reversed, not the individual strings.
For instance, as we go from the order-$2$ code $\langle x_0, \ x_1,
\ x_2, \ x_3 \rangle$ to the order-$3$ code, we concatenate that
sequence with $\langle x_3, \ x_2, \ x_1, \ x_0 \rangle$.)
\item
Augment each length-$k$ string in one copy of the order-$k$ Gray code
to length $(k+1)$ by prepending a $0$ to each string; and, augment
each length-$k$ string in the other (reversed) copy of the order-$k$
Gray code to length $(k+1)$ by prepending a $1$ to each string.
\end{itemize}
The following table illustrates the first few steps of this process.
\begin{equation}
\label{eq:gray-code}
 {\small
\begin{array}{|c|c|c|c|}
\hline
\mbox{Order } \ 1
  & \mbox{Order } \ 2
  & \mbox{Order } \ 3
  & \mbox{Order } \ 4 \\
\hline
0   & 00   & 000  &  0000 \\ 
1   & 01   & 001  &  0001 \\
    & 11   & 011  &  0011 \\
    & 10   & 010  &  0010 \\
    &      & 110  &  0110 \\
    &      & 111  &  0111 \\
    &      & 101  &  0101 \\
    &      & 100  &  0100 \\
    &      &      &  1100 \\  
    &      &      &  1101 \\  
    &      &      &  1111 \\  
    &      &      &  1110 \\  
    &      &      &  1010 \\  
    &      &      &  1011 \\  
    &      &      &  1001 \\  
    &      &      &  1000 \\  
\hline
\end{array} }
\end{equation}

We now sketch a proof that for each index $n \in \N^+$, the order-$n$
Gray code sequence specifies a Hamiltonian cycle in $\q_n$; exercises
will give the reader the opportunity to fill in details.  We verify
the following two assertions in turn:
\begin{enumerate}
\item
{\it The order-$n$ Gray code contains all $2^n$ length-$n$ binary
  strings.}
\item
{\it Every pair of cyclically adjacent strings in the order-$n$ Gray
  code differ in a single bit-position.}
\end{enumerate}

(1) We sketch the induction.  When $n=1$, the Gray code consists of
the two distinct strings $0$ and $1$.  Assume that the assertion holds
for $n=k$.  The order-$(k+1)$ code is obtained by taking two copies of
the order-$k$ code and prepending $0$ to the strings in one copy and
$1$ to the strings in the other copy.  The $2^k$ distinct binary
strings from the order-$k$ code thereby produce $2^{k+1}$ distinct
binary strings in the order-$(k+1)$ code.

(2) We distinguish three situations.  Let the adjacent strings be
string $x$, which appears in position $i$ of the code, and string $y$,
which appears in position $i+1 \bmod 2^n$ of the code.
  \begin{itemize}
  \item
Say that $i = 2^n-1$.  In this case $x$ is the last string in the
code, and $y$ is the first string.  By the ``refective'' nature of the
construction of the code, we know that $x = 1z$ and $y = 0z$ for some
length-$(n-1)$ binary string $z$.  Strings $x$ and $y$ therefore
differ in precisely one bit-position, namely, bit-position $0$.

  \item
Precisely the same argument shows that when $i = 2^{n-1} -1$, strings
$x$ and $y$ again differ precisely in bit-position $0$.

  \item
In all other cases, namely, when $i \in \{0,1, \ldots, 2^n-1\}
\setminus \{2^{n-1} -1, 2^n-1\}$, strings $x$ and $y$ share the same
first bit-position.  In fact, for some bit $\beta \in \{0,1\}$, $x =
\beta u$ and $y = \beta v$ for length-$(n-1)$ binary strings $u$ and
$v$ which are cyclically adjacent in the order-$(n-1)$ Gray code.  By
an inductive argument, $u$ and $v$ differ in precisely one
bit-position---which means that $x$ and $y$ also differ in precisely
one bit-position.
  \end{itemize}

\medskip

\noindent {\bf (e)}
By Proposition~\ref{thm:deBruin-linegraph}, each de Bruijn network
$\d_n$ is the line-digraph of the next bigger de Bruijn network,
$\d_{n+1}$.  Therefore, by definition of ``line (di)graph'', the fact
that $\d_n$ is (directed)-Eulerian
(Corollary~\ref{thm:deBruijn-Eulerian}) means that $\d_{n+1}$ is
(directed)-Hamiltonian.  \qed
\end{proof}

\bigskip




 cycles in general connected
graphs

**HERE


\paragraph{\small\sf C. Test general graphs for Hamiltonianicity}



\subsubsection{Hamiltonianicity in weighted graphs: The Traveling
  Salesman Problem}
\label{sec:TSP}

Hamiltonian
This problem is the traveling salesman problem, called TSP in short.
It corresponds to determine a minimal hamiltonian cycle in a weighted complete graphs $K_n$.
Obviously, $K_n$ is hamiltonian (it exists $n!$ such hamiltonian paths), thus, the question here is to determine the minimum one. 

TSP is a classical problem in Operational Research.
Let us consider a saleswoman who wants to organize the visit of her clients as best as possible.
It consists in visiting them in various cities with her vehicle. 
Of course, she must go in every city and her objective is to minimize the total distance done in the tour. 
The only information she has is the list of the cities and a map with all inter-cities distances. 
We assume a \textit{Euclidian distance} (for instance the weights correspond to number of kilometers between two cities).
This property means that the straight line is always the minimum distance, or in other words that the distance between two vertices/cities
is larger if the path is going through any other vertex. 
%More formally, the input of the problem is a weighted matrix with an infinite weight on the diagonal.
\bigskip

\noindent {\bf Proposition.}
The solution of Christofides algorithm is not worse than $\frac{3}{2}$ time the optimal tour.
\bigskip

Let us construct an efficient solution for this problem. It is well-known that TSP is a hard problem, 
that means we can not expect a polynomial time algorithm which solves exactly the problem, unless $\mathcal{P} = \mathcal{NP}$. 
Fig.~\ref{fig:perfectMatchingInitial} presents an example of euclidian TSP with $n=7$ cities. 
\begin{figure}[hbt]
\begin{center}
       \includegraphics[scale=0.8]{FiguresGraph/christofides1}
       \caption{Example of an instance of TSP with 7 cities.}
              \label{fig:christofidesInitial}
\end{center}
\end{figure}

Let us construct a good solution (not \textit{too far} from the optimal) in polynomial time. 
Let us denote by $\omega_G$ the weight of graph G (i.e. the sum of the weights on its edges). 
The Chritofides algorithm proceeds in three steps. 
\bigskip

\textbf{Step 1.} Determine a minimal weight spanning tree $T^*$. 
%A spanning tree of G is a tree (connected graph with no cycle) with the same set of vertices as G. 
As we recalled in the preliminaries, a minimal weight spanning tree can be determined in polynomial time. 
\bigskip

$\omega_{T^*}$ is a lower bound of the value of the optimal tour $\omega_{H^*}$. 
Indeed, $H^*$ is a cycle, then, removing any edge in $H^*$ leads to a chain, which is a particular spanning tree.
As $T^*$ is the minimal spanning tree, we have:
$\omega_{T^*} \leq \omega_{H^*}$.

\begin{figure}[hbt]
\begin{center}
       \includegraphics[scale=0.6]{FiguresGraph/christofides2}
       \caption{Construction of an optimal spanning Tree $T^*$.}
              \label{fig:christofidesSpanningTree}
\end{center}
\end{figure}


\textbf{Step 2.} Consider now the set $V_{odd}$ of the vertices of $T^*$ whose degrees are odd. 

We proved in the preliminary properties that the cardinality of $V_{odd}$ is even. 

Let us construct the perfect matching $C^*$ of minimum weight between the vertices in $V_{odd}$. 
Fig.~\ref{fig:AllPerfectMatchings} shows all possible perfect matchings on the previous example, the optimal one (with minimal weight) is represented in bold. 

Fig.~\ref{fig:christofidesPerfectMatching} illustrates the graph obtained by considering the edges of both $T^*$ and $C^*$. 
\begin{figure}[hbt]
\begin{center}
       \includegraphics[scale=0.6]{FiguresGraph/christofides3}
       \caption{Adding the optimal perfect matching $C^*$ to the minimal spanning tree $T^*$.}
              \label{fig:christofidesPerfectMatching}
\end{center}
\end{figure}

Let us now determine a lower bound of the optimal tour $H^*$ (represented in Fig.~\ref{fig:perfectMatchingInitial}).

$2 \omega_{C^*}$ is a lower bound of the value of the optimal tour ($\omega_{C^*} \leq \frac{1}{2} \omega_{H^*}$). 
Indeed, consider first the perfect matching $C^*$.
As its vertices belong to $H^*$, $\omega_{C*}$ is lower than the piece of hamiltonian tour contained between these vertices
because of the euclidian property (see Fig.~\ref{fig:perfectMatchingC*}).
Similarly for the \textit{complementary} perfect matching $C$ (Fig.~\ref{fig:perfectMatchingC}).  
Thus, the weight of the cycle formed by the concatenation of both perfect matchings is lower than the hamiltonian tour $\omega_{C^* \bigcup C} \leq \omega_{H^*}$.
Moreover, as $C^*$ is the minimum perfect matching, we have $\omega_{C^*} \leq \omega_{C}$, this concludes the proof.


\begin{figure}[hbt]
\begin{center}
       \includegraphics[scale=0.7]{FiguresGraph/perfectmatching1}
       \caption{An optimal hamiltonian cycle $H^*$.}
              \label{fig:perfectMatchingInitial}
\end{center}
\end{figure}

\begin{figure}[hbt]
\begin{center}
       \includegraphics[scale=0.7]{FiguresGraph/perfectmatching2}
       \caption{Perfect matching $C^*$ between the vertices of odd degrees.}
              \label{fig:perfectMatchingC*}
\end{center}
\end{figure}

\begin{figure}[hbt]
\begin{center}
       \includegraphics[scale=0.7]{FiguresGraph/perfectmatching3}
       \caption{Cycle $C^* \bigcup C$ (in dashed and bold).}
              \label{fig:perfectMatchingC}
\end{center}
\end{figure}

\bigskip

\textbf{Step 3.} 
All the vertices of $T^* \cup C^*$ have an even degree since we added an edge of $C^*$ to every odd degree vertices of $T^*$. 
We are now going to transform this graph by replacing iteratively the high degree vertices by shortcuts, which decreases the degree until reaching $2$. 

While it exists a vertex of degree greater than 4, we remove two of these consecutive edges and replace them by the opposite edge of this triangle 
without disconnecting the graph. There are $2k$ ways to remove $2$ edges and replace them by the triangle edge. Some of them disconnect the graph
and thus, must be avoided. 
Fig.~\ref{fig:christofidesFinalStep1} shows such a transformation on the previous example, 
Fig.~\ref{fig:christofidesFinalStep2} shows a valid transformation.

\begin{figure}[hbt]
\begin{center}
       \includegraphics[scale=0.6]{FiguresGraph/christofides4}
       \caption{Reduction of the degree in $T^* \bigcup C^*$, disconnected solution.}
              \label{fig:christofidesFinalStep1}
\end{center}
\end{figure}

\begin{figure}[hbt]
\begin{center}
       \includegraphics[scale=0.6]{FiguresGraph/christofides5}
       \caption{Reduction of the degree in $T^* \bigcup C^*$, connected solution.}
       \label{fig:christofidesFinalStep2}
\end{center}
\end{figure}

This process leads to a feasible tour. 
Such transformations do not increase the total weight.

Finally, 
as $\omega_{T^*} \leq \omega_{H^*}$ and $\omega_{C^*} \leq 1/2 \omega_{H^*}$,
we deduce that the value of such a tour is lower than $3/2 \omega_{H^*}$.

\section{Advanced Topics}

\subsection{Graphs with evolving structure}

Any course on algorithms will discuss graphs, especially trees, that
evolve over time.  Such structures arise in the study of ``classical''
algorithmic topics such minimum-spanning-tree and branch-and-bound
algorithms, as well as in the study of more modern topics such as
social networks and internetworks.  For the most part, the mathematics
already appearing in this essay suffices for these studies: the students
must assimilate new algorithmic notions, not new mathematics.  That
said, students will be challenged to utilize the mathematical devices
that they have (hopefully) mastered in new, more sophisticated, ways.
Instructors who wish to lead their students to even a casual
understanding of emerging modalities and platforms for computing are
thereby challenged to teach required mathematical preliminaries using
exemplars that include these new modalities and exemplars.

\subsection{Chromatic number}


%The chromatic number of a graph is defined as the minimum number of colors for coloring a graph. It is a NP-hard problem. However, there are good greedy approximation algorithms.


\subsection{Graph decomposition}


A fundamental variety of relevant notions within the study of graphs
reside in the notions known in various contexts via terms such as {\em
  graph separators} or {\em graph bisection}.  The key idea that
underlies these notions is that certain graph-theoretic structures
interconnect their graphs' constituent nodes more or less densely ---
and the type and level of interconnectivity has important algorithmic
consequences.  In such situations, the student must understand how the
phenomenon/a modeled by the graphs of interest are elucidated by the
way a graph can be broken into subgraphs by excising nodes or edges.
When discussing communication-related structures, for instance, graph
are often used to model the individual pairwise communications that
must occur in order to accomplish the desired overall communication
(such as a broadcast).  There is often a provable tradeoff between the
number of such pairwise communications and the overall time for the
completion of the overall task.  As another example, when discussing
social networks, one can pose questions such as: which node in a
network is best to connect to (when joining the network) in order to
best facilitate one's interactions or influence within the community.
The latter topic leads, e.g., to the study of {\em power-law}
networks, a topic that would not be studied in depth in any early
course; indeed, the structure of these networks is not yet well
understood even in advanced settings.



\subsection{Hypergraphs}

When studying certain computing-related topics, one will
need a generalization of graphs called {\em hypergraphs}.  A
hypergraph has nodes that are analogous to the nodes of a graph, but
in place of edges a hypergraph has {\em hyperedges}.  Each hyperedge
is a set of nodes whose size is not restricted to $2$; thus,
hypergraphs represent internode relationships that are not ``binary''.
A simple example can be framed by describing {\em bus-connected}
systems, such as occur in certain genres of digital circuits and
certain message-passing systems.  The underlying idea is that nodes
that coreside in a hyperedge represent agents that ``hear'' all
messages simultaneously, or equi-potential points in a network.
Because of their inherent complexity, hypergraphs as graph-theoretic
objects are usually relegated to advanced courses, but specific
concrete instantiations, exemplified by bus-oriented communication and
digital circuits should be accessible even to early students.


